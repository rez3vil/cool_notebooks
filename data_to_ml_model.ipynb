{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:42:43.741039Z",
     "start_time": "2020-12-19T06:42:43.723152Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# METADATA:\n",
    "__author__='Leela Sarath Kumar Konda'\n",
    "#########################################################################################################\n",
    "# README                                                                                                #\n",
    "#########################################################################################################\n",
    "# Before executing this code install the following                                                      #\n",
    "#                                                                                                       #\n",
    "# 1) postgresql                                                                                         #\n",
    "#   linux            - sudo apt install postgresql postgresql-contrib                                   #\n",
    "#                    - sudo systemctl start postgresql                                                  #\n",
    "#   windows          - download the file from                                                           #\n",
    "#                    - https://www.enterprisedb.com/downloads/postgres-postgresql-downloads             #\n",
    "#   if you are unable to install it then install chembl-webresource-client by using the command given   #\n",
    "#   in the below optional section                                                                       #\n",
    "#                                                                                                       #\n",
    "# 2) chembl sql dump - Download the file from ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/latest/ #\n",
    "#   1. Log into PostgreSQL database server where you intend to load chembl data and run the following   #\n",
    "#   command to create new database:                                                                     #\n",
    "#   pgdb=# create database chembl_27;                                                                   #\n",
    "#   2. Logout of database and run the following command to load data. You will need to replace          #\n",
    "#   USERNAME, HOST and PORT with local settings. Depending on your database setup you may not need      #\n",
    "#   the host and port arguments.                                                                        #\n",
    "#   $> pg_restore --no-owner -h HOST -p PORT -U USERNAME -d chembl_27 chembl_27_postgresql.dmp          #\n",
    "#                                                                                                       #\n",
    "# 3) anaconda        - Download the file from https://www.anaconda.com/ and                             #\n",
    "#                    - follow the given instructions                                                    #\n",
    "#                                                                                                       #\n",
    "# 4) sqlalchemy      - pip install SQLAlchemy                                                           #\n",
    "#                                                                                                       #\n",
    "# 5) psycopg2        - pip install psycopg2                                                             #\n",
    "#                                                                                                       #\n",
    "# 6) rdkit           - conda install -c conda-forge rdkit                                               #\n",
    "#                                                                                                       #\n",
    "# 7) mordred         - pip install mordred                                                              #\n",
    "#                                                                                                       #\n",
    "# 8) MolVS           - pip install MolVS                                                                #\n",
    "#                                                                                                       #\n",
    "# 9) pycaret         - pip install pycaret                                                              #\n",
    "#                                                                                                       #\n",
    "# 10) ngboost        - pip install ngboost                                                              #\n",
    "#                                                                                                       #\n",
    "# 11) smogn          - pip install smogn                                                                #\n",
    "#                                                                                                       #\n",
    "# 12) java                                                                                              #\n",
    "#     linux          - sudo apt install default-jdk default-jre                                         #\n",
    "#     windows        - download the file from                                                           #\n",
    "#                    - https://www.oracle.com/in/java/technologies/javase-jdk15-downloads.html          #\n",
    "#                                                                                                       #\n",
    "# 13) psutil         - pip install psutil                                                               #\n",
    "#                                                                                                       #\n",
    "# 14) easygui        - pip install easygui                                                              #\n",
    "#                                                                                                       #\n",
    "#########################################################################################################\n",
    "#                                                                                                       #\n",
    "# optional packages to install                                                                          #\n",
    "#                                                                                                       #\n",
    "# 1) chembl-web     - pip install chembl-webresource-client                                             #\n",
    "#    if it throws any error while using chembl-webresource-client package after installing it by using  #\n",
    "#    pip. Try to re-install it using                                                                    #\n",
    "#                   - conda install -c conda-forge chembl_webresource_client                            #\n",
    "#                                                                                                       #\n",
    "# 2) PaDEL Descriptor python wrapper - pip install padelpy                                              #\n",
    "#                                                                                                       #\n",
    "# 3) weka python wrapper             - pip install python-weka-wrapper3                                 #\n",
    "#                                                                                                       #\n",
    "#########################################################################################################\n",
    "#                                                                                                       #\n",
    "# user input file                                                                                       #\n",
    "#                                                                                                       #\n",
    "# for user input csv file must contain following column names to execute the code properly in any       #\n",
    "# sequence. column names = mol_id, standard_type, pvalue, canonical_smiles                              #\n",
    "#                                                                                                       #\n",
    "#########################################################################################################\n",
    "# for AttributeError: 'Remove_100' object has no attribute 'columns_to_drop' use following command to fix\n",
    "# pip install --upgrade --user git+https://github.com/pycaret/pycaret.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:09.831300Z",
     "start_time": "2020-12-19T06:42:43.751412Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "from os.path import join\n",
    "from os.path import splitext\n",
    "from os.path import basename\n",
    "import platform\n",
    "from psutil import virtual_memory\n",
    "import easygui\n",
    "\n",
    "from sqlalchemy import create_engine #RDBS connections\n",
    "from chembl_webresource_client.new_client import new_client\n",
    "import pandas\n",
    "import numpy\n",
    "import re\n",
    "from subprocess import call\n",
    "import itertools\n",
    "from xml.etree import ElementTree as ET\n",
    "from collections import Counter\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.SaltRemover import SaltRemover\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Avalon.pyAvalonTools import GetAvalonFP\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "from rdkit import SimDivFilters\n",
    "\n",
    "from molvs import Standardizer\n",
    "from molvs.standardize import standardize_smiles\n",
    "\n",
    "from mordred import Calculator\n",
    "from mordred import descriptors\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "#from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.linear_model import LassoCV\n",
    "#from sklearn.linear_model import Lasso\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from lightgbm import LGBMClassifier\n",
    "import scipy.stats as stats\n",
    "\n",
    "# import imbalance learn oversampling techniques\n",
    "from imblearn.over_sampling import *\n",
    "# SMOTE for Regression with Gaussian Noise. similar to imblearn but for regression\n",
    "import smogn\n",
    "#import pycaret classification module\n",
    "from pycaret import classification\n",
    "#import pycaret regression module\n",
    "from pycaret import regression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from ngboost import NGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:09.874996Z",
     "start_time": "2020-12-19T06:43:09.839725Z"
    },
    "code_folding": [
     0,
     20
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_assay_conc(assay_desc, mol_wt):\n",
    "    pattern = 'at(| | <| >)(\\d+(\\.\\d+)?) (nM|uM|mM|ug/mL|ug/ml)'\n",
    "    pattern = re.search(pattern, assay_desc)\n",
    "    if pattern is not None:\n",
    "        pattern = pattern[0].replace('at ','')\n",
    "        molar = pattern.split(' ')[1]\n",
    "        if '<' in pattern.split(' ')[0] or '>' in pattern.split(' ')[0]:\n",
    "            pattern = pattern.translate(str.maketrans({'<': '', '>': ''}))\n",
    "        if molar == 'nM':\n",
    "            return(float(pattern.split(' ')[0])/(1000))\n",
    "        elif molar == 'mM':\n",
    "            return(float(pattern.split(' ')[0])*(1000))\n",
    "        elif molar == 'uM':\n",
    "            return(float(pattern.split(' ')[0]))\n",
    "        elif molar == 'ug/mL' or molar == 'ug/ml':\n",
    "            return(float(pattern.split(' ')[0])/mol_wt)\n",
    "        #else: \n",
    "        # add other unit types as well if required\n",
    "        #return\n",
    "\n",
    "def std_conversion(std_val, std_unit, mol_wt, counter):\n",
    "    if std_unit == 'nM':\n",
    "        pass\n",
    "    elif std_unit == 'uM':\n",
    "        std_val = (float(std_val) * 1000)\n",
    "    elif (std_unit == 'ng.mL-1'\n",
    "          or std_unit == 'ng.ml-1'\n",
    "          or std_unit == 'ng/mL'\n",
    "          or std_unit == 'ng/ml'):\n",
    "        std_val = (float(std_val) / mol_wt)\n",
    "    elif (std_unit == 'ug.mL-1'\n",
    "          or std_unit == 'ug.ml-1'\n",
    "          or std_unit == 'ug/mL'\n",
    "          or std_unit == 'ug/mL'):\n",
    "        std_val = ((float(std_val) / mol_wt) * 1000)\n",
    "    else:\n",
    "        #print('add this \"{}\" new standard units'.format(std_units))\n",
    "        # 'p.p.m', 'ppm', 'ug cm**-2', 'ug disk-1', 'ug mg-1', 'microg', 'ug', 'microg/cm3', 'uL/ml'\n",
    "        # '10'-2micromol/ml', '10'-2 umol/ml', '10'-2umol', '10'-3uM/ml', '10'-3micromol/ml'\n",
    "        counter += 1\n",
    "    return(std_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:09.947200Z",
     "start_time": "2020-12-19T06:43:09.881362Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_raw_data(records, counter, max_molwt, std_type):\n",
    "    records['assay_conc_uM'] = [get_assay_conc(record, mol_wt)\n",
    "                                if std_type == 'Inhibition' \n",
    "                                else numpy.nan \n",
    "                                for record, mol_wt in zip(records.assay_description\n",
    "                                                          , records.mol_wt)]\n",
    "    records['value'] = [std_conversion(std_val, std_unit\n",
    "                                       , mol_wt, counter)\n",
    "                        if std_type != 'Inhibition' \n",
    "                        else numpy.nan \n",
    "                        for std_val, std_unit, mol_wt in zip(records.standard_value\n",
    "                                                             , records.standard_units\n",
    "                                                             , records.mol_wt)]\n",
    "    # replace '>=' to '>' and '<=' to '<' in RELATION column to ease the grouping of RELATION column\n",
    "    # make changes in raw data\n",
    "    records.standard_relation.replace({'>=': '>', '<=': '<'}, inplace=True)\n",
    "    # convert data type of potency column from object to numeric\n",
    "    records[['value', 'assay_conc_uM']] = records[['value', 'assay_conc_uM']].apply(pandas.to_numeric)#.astype('float64')\n",
    "    # replace empty cells with Zeros and make changes in raw data\n",
    "    records.document_year.fillna(0, inplace=True)\n",
    "    # replace empty entries in raw data with #. eg:- '' to # and make changes in raw data\n",
    "    records.standard_relation.fillna('#', inplace=True)\n",
    "    return(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:09.995225Z",
     "start_time": "2020-12-19T06:43:09.954387Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def customsort(group_keys):\n",
    "    #assay_sort = {'B':0, 'F':1, 'A':2, 'T':3, 'P':4, 'U':5}\n",
    "    #sign_sort = {'=':0, '#':1, '<':2, '>':3}\n",
    "    try_dict = {}\n",
    "    for key in group_keys:\n",
    "        if (key == 'B' \n",
    "            or key == '=' \n",
    "            or key == 'vStrong' \n",
    "            or key == 4): try_dict[key]=0\n",
    "        elif (key == 'F' \n",
    "              or key == '#'\n",
    "              or key == 'Strong'\n",
    "              or key == 3): try_dict[key]=1\n",
    "        elif (key == 'A'\n",
    "              or key == '<'\n",
    "              or key == 'Moderate'\n",
    "              or key == 2): try_dict[key]=2\n",
    "        elif (key == 'T'\n",
    "              or key == '>'\n",
    "              or key == 'Weak'\n",
    "              or key == 1): try_dict[key]=3\n",
    "        elif (key == 'P'\n",
    "              or key == 'Inactive'\n",
    "              or key == 0): try_dict[key]=4\n",
    "        elif (key == 'U'\n",
    "              or key == 'vInactive'\n",
    "              or key == 40): try_dict[key]=5\n",
    "        elif (key == 'sInactive'\n",
    "              or key == 30): try_dict[key]=6\n",
    "        elif (key == 'mInactive'\n",
    "              or key == 20): try_dict[key]=7\n",
    "        elif (key == 'wInactive'\n",
    "              or key == 10): try_dict[key]=8\n",
    "        else : try_dict[key]=9\n",
    "    sorted_dict = {key: value for key, value in sorted(try_dict.items(), key=lambda item: item[1])}\n",
    "    return(list(sorted_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.082375Z",
     "start_time": "2020-12-19T06:43:10.009427Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_unique_mols(raw_data, std_type):\n",
    "    # create a empty dataframe\n",
    "    unique_data = test_data = pandas.DataFrame()\n",
    "    id_groups = raw_data.groupby('mol_id', sort=False)\n",
    "    molids = id_groups.groups.keys()\n",
    "    for molid in molids:\n",
    "        idgroup = id_groups.get_group(molid)\n",
    "        dategroups = idgroup.groupby('document_year', sort=False)\n",
    "        # sort dates in descending order\n",
    "        dates = sorted(dategroups.groups.keys(), reverse=True)\n",
    "        date = dategroups.get_group(dates[0])\n",
    "        assays = date.groupby('assay_type', sort=False)\n",
    "        sorted_assays = customsort(assays.groups.keys())\n",
    "        assay = assays.get_group(sorted_assays[0])\n",
    "        signs = assay.groupby('standard_relation', sort=False)\n",
    "        sorted_signs = customsort(signs.groups.keys())\n",
    "        entry = signs.get_group(sorted_signs[0])\n",
    "        if len(entry) > 1: # len(entry) = number of rows\n",
    "            if std_type != 'Inhibition':\n",
    "                entry['pvalue'] = abs(numpy.log10(entry['value']*(10**-9)))\n",
    "                entry['pvalue_diff'] = abs(entry['pvalue'].diff())\n",
    "                lessthan_count = greaterthan_count = 0\n",
    "                gt_idx_list = []\n",
    "                for value_diff in entry['pvalue_diff']:\n",
    "                    if value_diff > 0.5:\n",
    "                        greaterthan_count += 1\n",
    "                        # index.items() throwing error and .tolist() .values giving list and array\n",
    "                        gt_idx_list = [idx for idx in entry[entry['pvalue_diff']==value_diff].index]\n",
    "                    else:\n",
    "                        lessthan_count += 1\n",
    "                if lessthan_count > greaterthan_count:\n",
    "                    entry.drop(gt_idx_list, inplace=True)\n",
    "                    entry.drop('pvalue_diff', axis=1, inplace=True)\n",
    "                    pvalue_mean = entry['pvalue'].mean()\n",
    "                    entry.drop_duplicates('mol_id', inplace=True)\n",
    "                    entry.pvalue = entry.pvalue.replace(entry.pvalue.iloc[0], pvalue_mean)\n",
    "                    # add entries to temporary dataframe\n",
    "                    unique_data = unique_data.append(entry, ignore_index=True)\n",
    "                else: # add to test set dataframe\n",
    "                    entry.drop('pvalue_diff', axis=1, inplace=True)\n",
    "                    entry.drop_duplicates('mol_id', inplace=True)\n",
    "                    # add entries to temporary dataframe\n",
    "                    test_data = test_data.append(entry, ignore_index=True)\n",
    "            else:\n",
    "                entry['pvalue'] = numpy.nan\n",
    "                lessthan_count = greaterthan_count = 0\n",
    "                gt_idx_list = []\n",
    "                for value_diff in entry['standard_value']:\n",
    "                    if value_diff >= 50:\n",
    "                        greaterthan_count += 1\n",
    "                        # index.items() throwing error and .tolist() .values giving list and array\n",
    "                        gt_idx_list = [idx for idx in entry[entry['standard_value']==value_diff].index]\n",
    "                    else:\n",
    "                        lessthan_count += 1\n",
    "                        gt_idx_list = [idx for idx in entry[entry['standard_value']==value_diff].index]\n",
    "                if lessthan_count == greaterthan_count:\n",
    "                    entry.drop_duplicates('mol_id', inplace=True)\n",
    "                    # add entries to temporary dataframe\n",
    "                    test_data = test_data.append(entry, ignore_index=True)\n",
    "                else: # add to test set dataframe\n",
    "                    entry = entry.loc[gt_idx_list]\n",
    "                    value_mean = entry['standard_value'].mean()\n",
    "                    entry.drop_duplicates('mol_id', inplace=True)\n",
    "                    entry.value = entry.value.replace(entry.value.iloc[0], value_mean)\n",
    "                    # add entries to temporary dataframe\n",
    "                    unique_data = unique_data.append(entry, ignore_index=True)                 \n",
    "        else:\n",
    "            if std_type != 'Inhibition':\n",
    "                entry['pvalue'] = abs(numpy.log10(entry['value']*(10**-9)))\n",
    "            else:\n",
    "                entry['pvalue'] = numpy.nan\n",
    "            # add entries to temporary dataframe\n",
    "            unique_data = unique_data.append(entry, ignore_index=True)\n",
    "    return(unique_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.115783Z",
     "start_time": "2020-12-19T06:43:10.094159Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def stdsmiles(smiles):\n",
    "    std = Standardizer()\n",
    "    return(std.standardize(Chem.MolFromSmiles(smiles)))\n",
    "\n",
    "def removesalt(std_mol):\n",
    "    remover = SaltRemover()\n",
    "    res = remover.StripMol(std_mol, dontRemoveEverything=True)\n",
    "    if res.GetNumAtoms() <= 1: return\n",
    "    else: return(Chem.MolToSmiles(res)) # return rdkit smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.169291Z",
     "start_time": "2020-12-19T06:43:10.123105Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_std_data(dataframe, name, cutoffs, choice):\n",
    "       \n",
    "    if not dataframe.empty or cutoffs is not None:\n",
    "        # drop the duplicate entries using 'ID' column\n",
    "        dataframe.drop_duplicates('mol_id', inplace=True)\n",
    "        # get standardized smiles\n",
    "        dataframe['standard_smiles'] = [removesalt(stdsmiles(smiles)) \n",
    "                                        for smiles in dataframe.canonical_smiles]\n",
    "        dataframe.drop_duplicates('standard_smiles', inplace=True)\n",
    "        multiclass = []\n",
    "        #options for the user to choose\n",
    "        options = ['ChEMBL target list', 'Molecules list']\n",
    "        \n",
    "        if choice == options[0]:\n",
    "            for std_value, assay_conc, percent_value, log_value in zip(dataframe.standard_type.values\n",
    "                                                                       , dataframe.assay_conc_uM.values\n",
    "                                                                       , dataframe.value.values\n",
    "                                                                       , dataframe.pvalue.values):\n",
    "                for i in range(0, len(cutoffs)):\n",
    "                    if std_value  == 'Inhibition':\n",
    "                        if assay_conc <= float(cutoffs[i]):\n",
    "                            if percent_value >= 50: multiclass.append(len(cutoffs)-i)\n",
    "                            else: multiclass.append((len(cutoffs)-i)*10)\n",
    "                            break\n",
    "                    else:\n",
    "                        if log_value >= abs(numpy.log10(float(cutoffs[i])*(10**-6))):\n",
    "                            multiclass.append(len(cutoffs)-i)\n",
    "                            break\n",
    "                else: multiclass.append(0)\n",
    "        else:\n",
    "            for log_value in dataframe.pvalue.values:\n",
    "                for i in range(0, len(cutoffs)):\n",
    "                    if log_value >= abs(numpy.log10(float(cutoffs[i])*(10**-6))):\n",
    "                            multiclass.append(len(cutoffs)-i)\n",
    "                            break\n",
    "                else: multiclass.append(0)\n",
    "        dataframe['multiclass'] = multiclass\n",
    "        print('|_ {} {} molecules were found'.format(dataframe.shape[0], name))\n",
    "    else:\n",
    "        print('|_ {} {} molecules were found'.format(dataframe.shape[0], name))\n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.233070Z",
     "start_time": "2020-12-19T06:43:10.178470Z"
    },
    "code_folding": [
     0,
     9,
     21,
     28
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_data_from_chembldb(target_id, targ_dir, cutoffs, thresholds, choice):\n",
    "    # define minimum molecular weight threshold\n",
    "    max_molwt = 850\n",
    "    print(target_id)\n",
    "    std_types = ['IC50', 'Ki', 'Inhibition']#,'MIC' and 'Potency' include as well and check the code running status\n",
    "    unique_data = test_data = pandas.DataFrame()\n",
    "    for std_type in std_types:\n",
    "        mol_query=\"\"\"\n",
    "        -- Retrieve compound activity details for a target\n",
    "        SELECT md.CHEMBL_ID AS mol_id\n",
    "            , cs.CANONICAL_SMILES\n",
    "            , d.YEAR as document_year\n",
    "            , act.STANDARD_TYPE\n",
    "            , act.STANDARD_RELATION\n",
    "            , act.STANDARD_VALUE\n",
    "            , act.STANDARD_UNITS\n",
    "            , a.ASSAY_TYPE\n",
    "            , a.DESCRIPTION AS assay_description\n",
    "            , cp.MW_FREEBASE as mol_wt\n",
    "            , td.CHEMBL_ID AS target_id\n",
    "            , td.PREF_NAME\n",
    "        FROM target_dictionary td\n",
    "            JOIN ASSAYS a ON td.TID = a.TID\n",
    "            JOIN ACTIVITIES act ON a.ASSAY_ID = act.ASSAY_ID\n",
    "            JOIN DOCS d ON act.DOC_ID = d.DOC_ID\n",
    "            JOIN MOLECULE_DICTIONARY md ON act.MOLREGNO = md.MOLREGNO\n",
    "            JOIN COMPOUND_STRUCTURES cs ON md.MOLREGNO = cs.MOLREGNO\n",
    "            JOIN COMPOUND_PROPERTIES cp ON cs.MOLREGNO = cp.MOLREGNO\n",
    "        WHERE cs.CANONICAL_SMILES IS NOT NULL\n",
    "            AND (act.STANDARD_VALUE IS NOT NULL\n",
    "                AND act.STANDARD_UNITS IS NOT NULL)\n",
    "            AND (NOT (act.STANDARD_TEXT_VALUE LIKE 'inconclusive'\n",
    "                    OR act.STANDARD_TEXT_VALUE LIKE 'undetermined')\n",
    "                OR act.STANDARD_TEXT_VALUE IS NULL)\n",
    "            AND a.CONFIDENCE_SCORE IN (9, 8)\n",
    "            AND cp.MW_FREEBASE <= '{}'\n",
    "            AND act.STANDARD_TYPE = '{}'\n",
    "            AND td.CHEMBL_ID = '{}';\n",
    "        \"\"\".format(max_molwt, std_type, target_id)\n",
    "        \n",
    "        records = pandas.read_sql(mol_query, engine)\n",
    "        #records['assay_conc_uM'] = ''\n",
    "        counter = 0\n",
    "        if records.empty: print('|_ For activity type {} 0 records were found'.format(std_type))\n",
    "        else:\n",
    "            print('|_ For activity type {} {} records were found'.format(std_type, records.shape[0]))\n",
    "            # get raw dataframe\n",
    "            raw_data = get_raw_data(records, counter, max_molwt, std_type)\n",
    "            print('|  |_ {} records were found in Raw data'.format(raw_data.shape[0]))\n",
    "            raw_data.to_csv('{}_{}_rawdata.csv'.format(join(targ_dir, target_id)\n",
    "                                                       , std_type), index=False)\n",
    "            # get unique molecule entries\n",
    "            unique_mols, test_mols = get_unique_mols(raw_data, std_type)\n",
    "            print('|  |_ {} unique records were found'.format(unique_mols.shape[0]))\n",
    "            print('|  |_ {} test records were found'.format(test_mols.shape[0]))\n",
    "            unique_mols.to_csv('{}_{}_uniquemols.csv'.format(join(targ_dir, target_id)\n",
    "                                                             , std_type), index=False)\n",
    "            test_mols.to_csv('{}_{}_testmols.csv'.format(join(targ_dir, target_id)\n",
    "                                                         , std_type), index=False)\n",
    "            unique_data = unique_data.append(unique_mols, ignore_index=True)\n",
    "            test_data = test_data.append(test_mols, ignore_index=True)                   \n",
    "    if not unique_data.empty:\n",
    "        std_records = get_std_data(unique_data, 'uniquedata', cutoffs, choice)\n",
    "        std_records.to_csv('{}_uniquedata.csv'.format(join(targ_dir, target_id)), index=False)\n",
    "    if not test_data.empty:\n",
    "        test_records = get_std_data(test_data, 'testdata', cutoffs, choice)\n",
    "        test_records.to_csv('{}_testdata.csv'.format(join(targ_dir, target_id)), index=False)\n",
    "    else: test_records=None\n",
    "    return(std_records, test_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.300233Z",
     "start_time": "2020-12-19T06:43:10.243137Z"
    },
    "code_folding": [
     0,
     7,
     25,
     28,
     34,
     38
    ]
   },
   "outputs": [],
   "source": [
    "def get_data_from_chemblwbc(target_id, targ_dir, cutoffs, thresholds, choice):\n",
    "    # define minimum molecular weight threshold\n",
    "    max_molwt = 850\n",
    "    print(target_id)\n",
    "    std_types = ['IC50', 'Ki', 'Inhibition']#,'MIC' and 'Potency' include as well and check the code running status\n",
    "    unique_data = test_data = pandas.DataFrame()\n",
    "    for std_type in std_types:\n",
    "        records = new_client.activity.filter(target_chembl_id=target_id\n",
    "                                             , standard_type=std_type\n",
    "                                             , confidence_score=9|8\n",
    "                                             , molecule_properties__mw_freebase__lte=850\n",
    "                                             , standard_value__isnull=False\n",
    "                                             , standard_units__isnull=False\n",
    "                                             , canonical_smiles__isnull=False\n",
    "                                            ).only(['molecule_chembl_id'\n",
    "                                                    , 'canonical_smiles'\n",
    "                                                    , 'document_year'\n",
    "                                                    , 'standard_relation'\n",
    "                                                    , 'standard_value'\n",
    "                                                    , 'standard_units'\n",
    "                                                    , 'assay_type'\n",
    "                                                    , 'assay_description'\n",
    "                                                    , 'standard_text_value'\n",
    "                                                    , 'target_chembl_id'\n",
    "                                                    , 'target_pref_name'])\n",
    "        records = [record for record in records if not (record['standard_text_value']=='inconclusive'\n",
    "                                                        or record['standard_text_value']=='undetermined'\n",
    "                                                        or record['standard_text_value']!=None)]\n",
    "        records = pandas.DataFrame(records, columns=['molecule_chembl_id', 'canonical_smiles'\n",
    "                                                     , 'document_year', 'type'\n",
    "                                                     , 'standard_relation', 'standard_value'\n",
    "                                                     , 'standard_units', 'assay_type'\n",
    "                                                     , 'assay_description', 'target_chembl_id'\n",
    "                                                     , 'target_pref_name'])\n",
    "        records.rename(columns={'molecule_chembl_id': 'mol_id', 'target_pref_name':'pref_name'\n",
    "                                , 'type':'standard_type', 'target_chembl_id':'target_id'\n",
    "                                , 'target_pref_name':'pref_name'}, inplace=True)\n",
    "        molwt=[]\n",
    "        for mol_id in records.mol_id.values:\n",
    "            props = new_client.molecule.filter(molecule_chembl_id=mol_id).only(['molecule_properties'])\n",
    "            for mw in props:\n",
    "                molwt.append(mw['molecule_properties']['mw_freebase'])\n",
    "        molwt = pandas.DataFrame(molwt, columns =['mol_wt'])\n",
    "        records = pandas.concat([records, molwt], axis=1)\n",
    "        counter = 0\n",
    "        if records.empty: print('|_ For activity type {} 0 records were found'.format(std_type))\n",
    "        else:\n",
    "            print('|_ For activity type {} {} records were found'.format(std_type, records.shape[0]))\n",
    "            # get raw dataframe\n",
    "            raw_data = get_raw_data(records, counter, max_molwt, std_type)\n",
    "            print('|  |_ {} records were found in Raw data'.format(raw_data.shape[0]))\n",
    "            raw_data.to_csv('{}_{}_rawdata.csv'.format(join(targ_dir, target_id)\n",
    "                                                       , std_type), index=False)\n",
    "            # get unique molecule entries\n",
    "            unique_mols, test_mols = get_unique_mols(raw_data, std_type)\n",
    "            print('|  |_ {} unique records were found'.format(unique_mols.shape[0]))\n",
    "            print('|  |_ {} test records were found'.format(test_mols.shape[0]))\n",
    "            unique_mols.to_csv('{}_{}_uniquemols.csv'.format(join(targ_dir, target_id)\n",
    "                                                             , std_type), index=False)\n",
    "            test_mols.to_csv('{}_{}_testmols.csv'.format(join(targ_dir, target_id)\n",
    "                                                         , std_type), index=False)\n",
    "            unique_data = unique_data.append(unique_mols, ignore_index=True)\n",
    "            test_data = test_data.append(test_mols, ignore_index=True)                   \n",
    "    if not unique_data.empty:\n",
    "        std_records = get_std_data(unique_data, 'uniquedata', cutoffs, choice)\n",
    "        std_records.to_csv('{}_uniquedata.csv'.format(join(targ_dir, target_id)), index=False)\n",
    "    if not test_data.empty:\n",
    "        test_records = get_std_data(test_data, 'testdata', cutoffs, choice)\n",
    "        test_records.to_csv('{}_testdata.csv'.format(join(targ_dir, target_id)), index=False)\n",
    "    else: test_records=None\n",
    "    return(std_records, test_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.331934Z",
     "start_time": "2020-12-19T06:43:10.308983Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def smi_to_sdf(std_records, target_id, targ_dir ):\n",
    "    # from the standard dataframe reads, the smiles and id column\n",
    "    # using RDkit functions converts smiles to sdf molecule\n",
    "    # includes the ID as name or title of the each entry\n",
    "    # and returns the sdf filename  \n",
    "    sd_filename = '{}.sdf'.format(join(targ_dir, target_id))\n",
    "    sdwriter = Chem.SDWriter(sd_filename)\n",
    "    for mol, title in zip(std_records.standard_smiles, std_records.mol_id):\n",
    "        mol = Chem.MolFromSmiles(mol)\n",
    "        hmol = Chem.AddHs(mol)\n",
    "        hmol.SetProp(\"_Name\", title.strip())\n",
    "        sdwriter.write(hmol)\n",
    "    sdwriter.close()\n",
    "    return(sd_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.370990Z",
     "start_time": "2020-12-19T06:43:10.337903Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_xml(fp_type):\n",
    "    \n",
    "    def indent(elem, level=0):\n",
    "        i = \"\\n\" + level*'    '\n",
    "        if len(elem):\n",
    "            if not elem.text or not elem.text.strip(): elem.text = i + '    '\n",
    "            if not elem.tail or not elem.tail.strip(): elem.tail = i\n",
    "            for elem in elem:\n",
    "                indent(elem, level+1)\n",
    "            if not elem.tail or not elem.tail.strip(): elem.tail = i\n",
    "        else:\n",
    "            if level and (not elem.tail or not elem.tail.strip()): elem.tail = i\n",
    "    root = ET.Element('Root')\n",
    "    group = ET.SubElement(root, 'Group')\n",
    "    group.set('name','Fingerprint')\n",
    "    descriptor = ET.SubElement(group, 'Descriptor')\n",
    "    descriptor.set('name',fp_type)\n",
    "    descriptor.set('value','true')\n",
    "    indent(root)\n",
    "    # create a new XML file with the results\n",
    "    mydata = ET.tostring(root)\n",
    "    data = ET.ElementTree(root)\n",
    "    xml_file = join(os.getcwd(), 'fp.xml')\n",
    "    data.write(xml_file, encoding='utf-8', method=\"xml\") #'    '\n",
    "    return(xml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.492167Z",
     "start_time": "2020-12-19T06:43:10.381834Z"
    },
    "code_folding": [
     33,
     64,
     85,
     146
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calc_desc_fp(sd_filename):\n",
    "    # calculates the descriptors using PaDEL, Mordred and rdkit\n",
    "    # generates individual pandas dataframes\n",
    "    # and return them as a dict\n",
    "    desc_frames = {}\n",
    "    # padel descriptor calculation:\n",
    "    # pass the smiles files\n",
    "    # PaDEL-Descriptor should be kept in working directory\n",
    "    _PADEL_PATH = join(os.getcwd(), 'PaDEL-Descriptor', 'PaDEL-Descriptor.jar')\n",
    "    _JCM_PATH = join(os.getcwd(), 'jcompound-mapper', 'jCMapperCLI.jar')\n",
    "\n",
    "    def pdl_desc_calc():\n",
    "        pdl_output_file = '{}_pdl_desc.csv'.format(splitext(sd_filename)[0])\n",
    "        # -maxruntime Maximum running time per molecule(in milliseconds). Use -1 for unlimited.\n",
    "        # 300000 milliseconds = 2 minutes\n",
    "        _PARAMETERS = \"-maxruntime 120000 -threads -1 -2d -removesalt \"\n",
    "        _PARAMETERS += \"-standardizenitro -detectaromaticity -retainorder \"\n",
    "        command = 'java -jar -splash:disable {}'.format(_PADEL_PATH)\n",
    "        command += ' {}'.format(_PARAMETERS)\n",
    "        command += ' -dir {}'.format(sd_filename)\n",
    "        command += ' -file {}'.format(pdl_output_file)\n",
    "        #running the command using subprocess.call\n",
    "        #call([command], shell=True)\n",
    "        os.system(command)\n",
    "        # removing the first column of the dataframe as it contains both name and class\n",
    "        # as comma separated and we are going to add them separately in the end\n",
    "        pdl_frame = pandas.read_csv(pdl_output_file)\n",
    "        pdl_frame.drop('Name', axis=1, inplace=True)\n",
    "        print(\"|  |_ PaDEL Descriptors calculation was completed\")\n",
    "        return (pdl_frame)\n",
    "\n",
    "    # mordred descriptor calculation:\n",
    "    # pass a list of molecules or the rdkit smiles molecule supplier\n",
    "    def mrd_desc_calc():\n",
    "        #create mrd descriptor calculator:\n",
    "        mrd_calc = Calculator(descriptors)\n",
    "        #pass the smiles input file to rdkit using SDMolSupplier from rdkit\n",
    "        mols = Chem.SDMolSupplier(sd_filename)\n",
    "        #pandas method to calculate multiple molecules( returns pandas dataframe):\n",
    "        mrd_frame = mrd_calc.pandas(mols, quiet=True)  # quiet=True is for donâ€™t show progress bar\n",
    "        print(\"|  |_ Mordred Descriptors calculation was completed\")\n",
    "        return (mrd_frame)\n",
    "\n",
    "    # rdkit descriptor calculation:\n",
    "    # pass a list of molecules or the rdkit smiles molecule supplier\n",
    "    def rdk_desc_calc():\n",
    "        # get the descriptors list to calculate:\n",
    "        desc_names = list(numpy.array(Descriptors._descList)[:, 0])\n",
    "        # create rdk descriptor calculator:\n",
    "        rdk_calc = MolecularDescriptorCalculator(desc_names)\n",
    "        #pass the smiles input file to rdkit using SDMolSupplier from rdkit\n",
    "        mols = Chem.SDMolSupplier(sd_filename)\n",
    "        rdk_desc = []\n",
    "        for mol in mols:\n",
    "            descriptor = rdk_calc.CalcDescriptors(mol)\n",
    "            # using itertools\n",
    "            items = list(itertools.chain(descriptor))\n",
    "            rdk_desc.append(items)\n",
    "\n",
    "        # rdk pandas dataframe:\n",
    "        rdk_frame = pandas.DataFrame(rdk_desc, columns=desc_names)\n",
    "        print(\"|  |_ RDKit Descriptors calculation was completed\")\n",
    "        return (rdk_frame)\n",
    "\n",
    "    def pdl_fp_calc(fp_type):\n",
    "        _fp_file = build_xml(fp_type)\n",
    "        #_fp_file = join(os.getcwd(), xml_file)\n",
    "        pdl_output_file = '{}_pdl_{}.csv'.format(splitext(sd_filename)[0], fp_type)\n",
    "        _PARAMETERS = \"-threads -1 -fingerprints -removesalt \"\n",
    "        _PARAMETERS += \"-standardizenitro -detectaromaticity -retainorder -descriptortypes \"\n",
    "        command = 'java -jar -splash:disable {}'.format(_PADEL_PATH)\n",
    "        command += ' {}{}'.format(_PARAMETERS, _fp_file)\n",
    "        command += ' -dir {}'.format(sd_filename)\n",
    "        command += ' -file {}'.format(pdl_output_file)\n",
    "        #running the command using subprocess.call\n",
    "        #call([command], shell=True)\n",
    "        os.system(command)\n",
    "        # padel descriptor output file to pandas data frame\n",
    "        pdl_frame = pandas.read_csv(pdl_output_file)\n",
    "        # removing the first column of the dataframe as it contains both name and class\n",
    "        # as comma separated and we are going to add them separately in the end\n",
    "        pdl_frame.drop('Name', axis=1, inplace=True)\n",
    "        print(\"|  |_ PaDEL {} fingerprints calculation was completed\".format(fp_type))\n",
    "        return (pdl_frame)\n",
    "\n",
    "    def rdk_fp_calc():\n",
    "        fps_frames = {}\n",
    "\n",
    "        #pass the smiles input file to rdkit using SDMolSupplier from rdkit\n",
    "        mols = Chem.SDMolSupplier(sd_filename)\n",
    "        # MorganFingerprint\n",
    "        mg_fp = [[bit for bit in AllChem.GetMorganFingerprintAsBitVect(mol, radius=2).ToBitString()]\n",
    "                 for mol in mols]\n",
    "        mg_fp_name = ['RDMFP{}'.format(i) for i in range(0, len(mg_fp[0]))]\n",
    "        mg_df = pandas.DataFrame(mg_fp, columns=mg_fp_name)\n",
    "        fps_frames['MorganFingerprint'] = mg_df\n",
    "        print(\"|  |_ RDKit MorganFingerprint calculation was completed\")\n",
    "        # RDKitFingerprint\n",
    "        rd_fp = [[bit for bit in Chem.RDKFingerprint(mol).ToBitString()] for mol in mols]\n",
    "        rd_fp_name = ['RDRFP{}'.format(i) for i in range(0, len(rd_fp[0]))]\n",
    "        rd_df = pandas.DataFrame(rd_fp, columns=rd_fp_name)\n",
    "        fps_frames['RDKitFingerprint'] = rd_df\n",
    "        print(\"|  |_ RDKit RDKitFingerprint calculation was completed\")\n",
    "        # HashedAtomPairFingerprint\n",
    "        ap_fp = [[bit for bit in AllChem.GetHashedAtomPairFingerprintAsBitVect(mol).ToBitString()]\n",
    "                 for mol in mols]\n",
    "        ap_fp_name = ['RDAFP{}'.format(i) for i in range(0, len(ap_fp[0]))]\n",
    "        ap_df = pandas.DataFrame(ap_fp, columns=ap_fp_name)\n",
    "        fps_frames['HashedAtomPairFingerprint'] = ap_df\n",
    "        print(\"|  |_ RDKit HashedAtomPairFingerprint calculation was completed\")\n",
    "        # HashedTopologicalTorsionFingerprint\n",
    "        tp_fp = [[bit for bit in AllChem.GetHashedTopologicalTorsionFingerprintAsBitVect(mol).ToBitString()]\n",
    "                 for mol in mols]\n",
    "        tp_fp_name = ['RDTFP{}'.format(i) for i in range(0, len(tp_fp[0]))]\n",
    "        tp_df = pandas.DataFrame(tp_fp, columns=tp_fp_name)\n",
    "        fps_frames['HashedTopologicalTorsionFingerprint'] = tp_df\n",
    "        print(\"|  |_ RDKit HashedTopologicalTorsionFingerprint calculation was completed\")\n",
    "        # ErGFingerprint\n",
    "        er_fp = [AllChem.GetErGFingerprint(mol) for mol in mols]\n",
    "        er_fp_name = ['RDEFP{}'.format(i) for i in range(0, len(er_fp[0]))]\n",
    "        er_df = pandas.DataFrame(er_fp, columns=er_fp_name)\n",
    "        fps_frames['ErGFingerprint'] = er_df\n",
    "        print(\"|  |_ RDKit ErGFingerprint calculation was completed\")\n",
    "        '''\n",
    "        # FingerprintMol\n",
    "        fp_fp = [[bit for bit in FingerprintMols.FingerprintMol(mol).ToBitString()] for mol in mols]\n",
    "        fp_fp_name = ['RDFFP{}'.format(i) for i in range(0, 2048)]# using fp_fp[0] instead 2048 creates an error \n",
    "                                                                  # \"AssertionError:/ValueError:\n",
    "                                                                  # * columns passed, passed data had * columns\"\n",
    "        fp_df = pandas.DataFrame(fp_fp, columns=[fp_fp_name])\n",
    "        fp_df.fillna(0, inplace=True)\n",
    "        fps_frames['FingerprintMol'] = fp_df\n",
    "        print(\"|  |_ RDKit FingerprintMol calculation was completed\")\n",
    "        '''\n",
    "        # AvalonFingerprint\n",
    "        av_fp = [[bit for bit in GetAvalonFP(mol).ToBitString()] for mol in mols]\n",
    "        av_fp_name = ['RDVFP{}'.format(i) for i in range(0, len(av_fp[0]))]\n",
    "        av_df = pandas.DataFrame(av_fp, columns=av_fp_name)\n",
    "        fps_frames['AvalonFingerprint'] = av_df\n",
    "        print(\"|  |_ RDKit AvalonFingerprint calculation was completed\")\n",
    "\n",
    "        # rdk pandas dataframe:\n",
    "        #rdk_frame = pandas.concat(fps_frames, axis=1)\n",
    "        print(\"|  |_ RDKit Fingerprints calculation was completed\")\n",
    "        return (fps_frames)\n",
    "    \n",
    "    def jcm_fp_calc(fp_type):\n",
    "        jcm_output_file = '{}_jcm_{}.csv'.format(splitext(sd_filename)[0], fp_type)\n",
    "        command = 'java -jar {}'.format(_JCM_PATH)\n",
    "        command += ' -f {}'.format(sd_filename)\n",
    "        command += ' -c {}'.format(fp_type)\n",
    "        command += ' -ff FULL_CSV'\n",
    "        command += ' -o {}'.format(jcm_output_file)\n",
    "        os.system(command)\n",
    "        jcm_frame = pandas.read_csv(jcm_output_file, header=None)\n",
    "        jcm_frame.drop(jcm_frame.columns[0], axis=1, inplace=True)\n",
    "        jcm_frame.columns = ['jCM-{}{}'.format(fp_type, i) for i in range(0, jcm_frame.shape[1])]\n",
    "        print(\"|  |_ jCompound-Mapper {} fingerprints calculation was completed\".format(fp_type))\n",
    "        return(jcm_frame)\n",
    "\n",
    "    #to calculate descriptors using padel descriptor jar file\n",
    "    pdl_frame = pdl_desc_calc()\n",
    "    desc_frames['padel'] = pdl_frame\n",
    "    #to calculate descriptors using mordred\n",
    "    mrd_frame = mrd_desc_calc()\n",
    "    desc_frames['mordred'] = mrd_frame\n",
    "    #to calculate descriptors using rdkit\n",
    "    rdk_frame = rdk_desc_calc()\n",
    "    desc_frames['rdkit'] = rdk_frame\n",
    "    #to calculate fingerprints using padel descriptor jar file\n",
    "    fingerprints = ['Fingerprinter', 'ExtendedFingerprinter'\n",
    "                    , 'EStateFingerprinter', 'GraphOnlyFingerprinter'\n",
    "                    , 'MACCSFingerprinter', 'PubchemFingerprinter'\n",
    "                    , 'SubstructureFingerprinter', 'KlekotaRothFingerprinter'\n",
    "                    , 'AtomPairs2DFingerprinter']\n",
    "    for fp_type in fingerprints:\n",
    "        pdl_fp_frame = pdl_fp_calc(fp_type)\n",
    "        desc_frames[fp_type] = pdl_fp_frame\n",
    "    #to calculate fingerprints using rdkit\n",
    "    rdk_fp_frame = rdk_fp_calc()\n",
    "    desc_frames.update(rdk_fp_frame)\n",
    "    #to calculate fingerprints using jCompoundMapper jar file\n",
    "    fingerprints = ['DFS', 'ASP', 'AT2D', 'CATS2D', 'PHAP2POINT2D'\n",
    "                    , 'PHAP3POINT2D', 'ECFP', 'ECFPVariant', 'LSTAR']#, 'SHED']\n",
    "    for fp_type in fingerprints:\n",
    "        jcm_fp_frame = jcm_fp_calc(fp_type)\n",
    "        desc_frames[fp_type+'Fingerprint'] = jcm_fp_frame\n",
    "    return(desc_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.532327Z",
     "start_time": "2020-12-19T06:43:10.502819Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_class(std_dataframe, dataframe, threshold, cutoffs):\n",
    "    dataframe = pandas.concat([std_dataframe.reset_index(drop=True)\n",
    "                               , dataframe.reset_index(drop=True)], axis=1)\n",
    "    if threshold == 'TNO': dataframe['class'] = dataframe.pvalue\n",
    "    elif threshold == 'TMC': dataframe['class'] = dataframe.multiclass\n",
    "    else:\n",
    "        for i  in range(0, len(cutoffs)):\n",
    "            if threshold == 'T{}'.format(cutoffs[i]):\n",
    "                dataframe['class'] = dataframe.multiclass.apply(lambda x: 1 if (x >= len(cutoffs)-i\n",
    "                                                                                and x<10) else 0)\n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.573455Z",
     "start_time": "2020-12-19T06:43:10.543028Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_sets(rows):\n",
    "    test_set_size = round(rows.shape[0] * 0.2)\n",
    "    # make a list of mols\n",
    "    mol_list = [Chem.MolFromSmiles(mol) for mol in rows.standard_smiles]\n",
    "    # make a list of fingerprints (fp)\n",
    "    fp_list = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, 2048) for mol in mol_list]  #fp length to 2048\n",
    "    start_with = 0\n",
    "    how_many_to_pick = test_set_size\n",
    "    mmp = SimDivFilters.MaxMinPicker()\n",
    "    picks = mmp.LazyBitVectorPick(fp_list, len(fp_list)\n",
    "                                  , start_with + how_many_to_pick\n",
    "                                  , list(range(start_with)))\n",
    "    trainframe = rows.drop(rows.index[picks])\n",
    "    testframe = rows.iloc[picks]\n",
    "    return(trainframe, testframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.616555Z",
     "start_time": "2020-12-19T06:43:10.586145Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_train_test_sets(dataframe, threshold, drop_cols):\n",
    "    train_frame = pandas.DataFrame()\n",
    "    test_frame = pandas.DataFrame()\n",
    "    \n",
    "    if threshold == 'TNO':\n",
    "        # check the highest count in the standard_type column values and return it\n",
    "        key_max = dataframe.standard_type.value_counts().idxmax()\n",
    "        # fetch rows equals to key_max only \n",
    "        max_type_rows = dataframe.loc[dataframe.standard_type.isin([key_max])]\n",
    "        trainframe, testframe = get_sets(max_type_rows)\n",
    "        train_frame = train_frame.append(trainframe, ignore_index=True)         \n",
    "        test_frame = test_frame.append(testframe, ignore_index=True)\n",
    "    else:\n",
    "        # get specific rows based on the Class column values\n",
    "        clas_group = dataframe.groupby('class')\n",
    "        for clas in clas_group.groups:\n",
    "            rows_selected = clas_group.get_group(clas)\n",
    "            if rows_selected.shape[0] < 5:\n",
    "                train_frame = train_frame.append(rows_selected, ignore_index=True)\n",
    "            else:\n",
    "                trainframe, testframe = get_sets(rows_selected)\n",
    "                train_frame = train_frame.append(trainframe, ignore_index=True)\n",
    "                test_frame = test_frame.append(testframe, ignore_index=True)\n",
    "    train_frame.drop(drop_cols, axis=1, inplace=True)\n",
    "    test_frame.drop(drop_cols, axis=1, inplace=True)\n",
    "    return(train_frame, test_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.656628Z",
     "start_time": "2020-12-19T06:43:10.626291Z"
    },
    "code_folding": [
     2,
     21,
     29
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data Preprocess\n",
    "# convert string to Nan\n",
    "def str_to_Nan(dataframe):\n",
    "    # to convert all non Numeric values to Nan\n",
    "    # and return the dataframe\n",
    "    # Iterate through columns of Pandas DataFrame\n",
    "    # Where string value exist replace with Nan\n",
    "\n",
    "    # Get list of DataFrame column names\n",
    "    #cols = list(dataframe)\n",
    "    # Loop through columns\n",
    "    for column in dataframe.columns:\n",
    "        if column != 'class':\n",
    "            # Transfer column to independent series\n",
    "            col_data = dataframe[column]\n",
    "            # Replace string data with Nan\n",
    "            string = pandas.to_numeric(col_data, errors='coerce')\n",
    "            dataframe[column] = string\n",
    "    return(dataframe)\n",
    "\n",
    "# remove the columns with all Nan values:\n",
    "def drop_all_Nan(dataframe):\n",
    "    # to remove columns with all Nan values\n",
    "    # and return the dataframe\n",
    "    data = str_to_Nan(dataframe)\n",
    "    dataframe = data.dropna(axis=1, how='all')  #, inplace=True)\n",
    "    return(dataframe)\n",
    "\n",
    "# Replace missing numerical data with median\n",
    "def fillNan(dataframe):\n",
    "    # to replace all Nan values with median of individual columns respectively\n",
    "    # and return the dataframe\n",
    "    data = drop_all_Nan(dataframe)\n",
    "    data.replace([numpy.inf, -numpy.inf], numpy.nan, inplace=True)\n",
    "    dataframe = data.fillna(data.median())\n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.720190Z",
     "start_time": "2020-12-19T06:43:10.678800Z"
    },
    "code_folding": [
     1,
     17
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scaling and normalization\n",
    "def data_transformation(set_name, desc_set, threshold):#frames\n",
    "    \n",
    "    transformed_frames = {}\n",
    "    # Data preprocessing\n",
    "    frame = fillNan(desc_set)\n",
    "    #drop columns with same value and consider remaining columns\n",
    "    frame = frame[[col for col in frame if not frame[col].nunique()==1]]\n",
    "    # Define X and y variables\n",
    "    X = frame.drop('class', 1)\n",
    "    y = frame['class']\n",
    "    # X = frame[frame.columns[:-1]]#.T\n",
    "    # y = frame[frame.columns[-1]]\n",
    "    # Extract feature names\n",
    "    feature_name = X.columns.tolist()\n",
    "    \n",
    "    # no data transformation\n",
    "    def no_transform():\n",
    "        ntframe = frame\n",
    "        return(ntframe)\n",
    "\n",
    "    # scaling\n",
    "    def standardize():\n",
    "        scaler = StandardScaler()\n",
    "        X_std = scaler.fit_transform(X)\n",
    "        X_frame = pandas.DataFrame(X_std, columns=feature_name)\n",
    "        stdframe = pandas.concat([X_frame, y], axis=1)\n",
    "        return(stdframe)\n",
    "\n",
    "    # robust scaling\n",
    "    def robustscale():\n",
    "        robscale = RobustScaler()\n",
    "        X_rbst = robscale.fit_transform(X)\n",
    "        X_frame = pandas.DataFrame(X_rbst, columns=feature_name)\n",
    "        rbstframe = pandas.concat([X_frame, y], axis=1)\n",
    "        return(rbstframe)\n",
    "\n",
    "    # minmax normalization\n",
    "    def normalize():\n",
    "        normalizer = MinMaxScaler()\n",
    "        X_norm = normalizer.fit_transform(X)\n",
    "        X_frame = pandas.DataFrame(X_norm, columns=feature_name)\n",
    "        normframe = pandas.concat([X_frame, y],axis=1)\n",
    "        return(normframe)\n",
    "    \n",
    "    if set_name in ['padel', 'mordred', 'rdkit']:\n",
    "        notrans = no_transform()\n",
    "        transformed_frames[threshold + '_notrans_'+ set_name]=notrans\n",
    "\n",
    "        std = standardize()\n",
    "        transformed_frames[threshold + '_std_'+ set_name]=std\n",
    "\n",
    "        rbst = robustscale()\n",
    "        transformed_frames[threshold + '_rbst_'+ set_name]=rbst\n",
    "\n",
    "        norm = normalize()\n",
    "        transformed_frames[threshold + '_minmax_'+ set_name]=norm\n",
    "\n",
    "    else:\n",
    "        notrans = no_transform()\n",
    "        transformed_frames[threshold + '_notrans_'+ set_name]=notrans\n",
    "    \n",
    "    return(transformed_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.801296Z",
     "start_time": "2020-12-19T06:43:10.738717Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# t.test two sample unequal variance (binary class), f-oneway anova test (multi class) and Kolmogorov-Smirnov(ks) test (continous class)\n",
    "def pvalue_calc(dataframe, threshold):\n",
    "    # to calculate the pvalue of each column using two sample unequal variance t.test\n",
    "    # for binary class dataset and f-oneway anova test for multiclass dataset\n",
    "    # filter columns that pass the criteria of pvalue <= 0.05\n",
    "    # transpose the filtered dataframe\n",
    "    # append it to the class column\n",
    "    # return the whole pvalue dataframe\n",
    "    if threshold == 'TNO':\n",
    "        pvalue_frame = pandas.DataFrame()\n",
    "        for col in dataframe.columns:\n",
    "            t, p = stats.kstest(dataframe[col], 'norm')\n",
    "            if p <= 0.05: pvalue_frame = pvalue_frame.append(dataframe[col])\n",
    "        if not pvalue_frame.empty:\n",
    "            pvalue_frame = pvalue_frame.T\n",
    "            pvalue_frame['class'] = dataframe['class']\n",
    "            return(pvalue_frame)\n",
    "        else:\n",
    "            print('|  |_No Descriptor is having a pvalue less than 0.05')\n",
    "            return(dataframe)\n",
    "    else:\n",
    "        pvalue_frame = pandas.DataFrame()\n",
    "        row_list = []\n",
    "        clas_group = dataframe.groupby('class')\n",
    "        for clas in clas_group.groups:\n",
    "            rows_selected = clas_group.get_group(clas)\n",
    "            row_list.append(rows_selected)\n",
    "        for col in dataframe.columns:\n",
    "            if col != 'class':\n",
    "                if len(row_list) == 2:\n",
    "                    t, p = stats.ttest_ind(row_list[0][col], row_list[1][col], equal_var=False)\n",
    "                    if p <= 0.05: pvalue_frame = pvalue_frame.append(dataframe[col])\n",
    "                elif len(row_list) == 3:\n",
    "                    t, p = stats.f_oneway(row_list[0][col], row_list[1][col], row_list[2][col])\n",
    "                    if p <= 0.05: pvalue_frame = pvalue_frame.append(dataframe[col])\n",
    "                elif len(row_list) == 4:\n",
    "                    t, p = stats.f_oneway(row_list[0][col], row_list[1][col]\n",
    "                                          , row_list[2][col], row_list[3][col])\n",
    "                    if p <= 0.05: pvalue_frame = pvalue_frame.append(dataframe[col])\n",
    "                elif len(row_list) == 5:\n",
    "                    t, p = stats.f_oneway(row_list[0][col], row_list[1][col]\n",
    "                                          , row_list[2][col], row_list[3][col]\n",
    "                                          , row_list[4][col])\n",
    "                    if p <= 0.05: pvalue_frame = pvalue_frame.append(dataframe[col])\n",
    "                elif len(row_list) == 6:\n",
    "                    t, p = stats.f_oneway(row_list[0][col], row_list[1][col]\n",
    "                                          , row_list[2][col], row_list[3][col] \n",
    "                                          ,row_list[4][col], row_list[5][col])\n",
    "                    if p <= 0.05: pvalue_frame = pvalue_frame.append(dataframe[col])\n",
    "                elif len(row_list) == 7:\n",
    "                    t, p = stats.f_oneway(row_list[0][col], row_list[1][col]\n",
    "                                          , row_list[2][col], row_list[3][col]\n",
    "                                          , row_list[4][col], row_list[5][col]\n",
    "                                          , row_list[6][col])\n",
    "                    if p <= 0.05: pvalue_frame = pvalue_frame.append(dataframe[col])\n",
    "        if not pvalue_frame.empty:\n",
    "            pvalue_frame = pvalue_frame.T\n",
    "            pvalue_frame['class'] = dataframe['class']\n",
    "            return(pvalue_frame)\n",
    "        else:\n",
    "            print('|  |_No Descriptor is having a pvalue less than 0.05')\n",
    "            return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.861457Z",
     "start_time": "2020-12-19T06:43:10.811853Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def group_replace(dataframe):\n",
    "    clas_group =  dataframe.groupby('class')\n",
    "    sorted_clas = customsort(clas_group.groups.keys())\n",
    "    '''\n",
    "    for group in sorted_clas:\n",
    "        for i in range(0, len(sorted_clas)):\n",
    "            if group == sorted_clas[i]:\n",
    "                dataframe['class'].replace({group: len(sorted_clas)-i}, inplace=True)\n",
    "                break\n",
    "    '''\n",
    "    for group in sorted_clas:\n",
    "        if group == 'vStrong': dataframe['class'].replace({group: 4}, inplace=True)\n",
    "        elif group == 'Strong': dataframe['class'].replace({group: 3}, inplace=True)\n",
    "        elif group == 'Moderate': dataframe['class'].replace({group: 2}, inplace=True)\n",
    "        elif (group == 'Weak'\n",
    "              or group == 'Active'): dataframe['class'].replace({group: 1}, inplace=True)\n",
    "        elif group == 'Inactive': dataframe['class'].replace({group: 0}, inplace=True)\n",
    "        elif group == 'vInactive': dataframe['class'].replace({group: 40}, inplace=True)\n",
    "        elif group == 'sInactive': dataframe['class'].replace({group: 30}, inplace=True)\n",
    "        elif group == 'mInactive': dataframe['class'].replace({group: 20}, inplace=True)\n",
    "        elif group == 'wInactive': dataframe['class'].replace({group: 10}, inplace=True)\n",
    "        elif group == 4: dataframe['class'].replace({group: 'vStrong'}, inplace=True)\n",
    "        elif group == 3: dataframe['class'].replace({group: 'Strong'}, inplace=True)\n",
    "        elif group == 2: dataframe['class'].replace({group: 'Moderate'}, inplace=True)\n",
    "        elif group == 1:\n",
    "            if len(clas_group) == 2: dataframe['class'].replace({group: 'Active'}, inplace=True)\n",
    "            else: dataframe['class'].replace({group: 'Weak'}, inplace=True)\n",
    "        elif group == 0: dataframe['class'].replace({group: 'Inactive'}, inplace=True)\n",
    "        elif group == 40: dataframe['class'].replace({group: 'vInactive'}, inplace=True)\n",
    "        elif group == 30: dataframe['class'].replace({group: 'sInactive'}, inplace=True)\n",
    "        elif group == 20: dataframe['class'].replace({group: 'mInactive'}, inplace=True)\n",
    "        elif group == 10: dataframe['class'].replace({group: 'wInactive'}, inplace=True)\n",
    "\n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:10.890116Z",
     "start_time": "2020-12-19T06:43:10.865809Z"
    },
    "code_folding": [
     1,
     5,
     28
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# WEKA\n",
    "def listToString(s):\n",
    "    # return string   \n",
    "    return('{{{}}}'.format(','.join(s)))\n",
    "\n",
    "def dataframetoarff(frame, threshold):\n",
    "    if threshold == 'TNO': frame = frame\n",
    "    else: frame = group_replace(frame) \n",
    "    arff = join(os.getcwd(), 'temp.arff')\n",
    "    rows = frame.to_csv(header=None, index=None).split('\\n')\n",
    "    f = open(arff, \"w\")\n",
    "    f.write('@relation temp\\n\\n')\n",
    "    for name in frame.columns:\n",
    "        if name != 'class': f.write('@attribute {} numeric\\n'.format(name))#numeric REAL real\n",
    "        else:\n",
    "            if threshold == 'TNO': f.write('@attribute {} numeric\\n'.format(name))#nominal numeric REAL real\n",
    "            else:\n",
    "                clas_group =  frame.groupby('class')\n",
    "                sorted_clas = customsort(clas_group.groups.keys())\n",
    "                dtyp = listToString(sorted_clas)\n",
    "                f.write('@attribute {} {}\\n'.format(name, dtyp))\n",
    "    f.write('@data\\n')\n",
    "    for row in rows:\n",
    "        f.write('{}\\n'.format(row))\n",
    "    f.close()\n",
    "    return(arff)\n",
    "\n",
    "# arff file to pandas dataframe;\n",
    "def arfftodataframe(arffFile, threshold):\n",
    "    # total memory in bytes are converted to gigabytes and 70% is going to provide for weka\n",
    "    memory = round(((virtual_memory().total)/1024**3)*0.7)\n",
    "    csv = join(os.getcwd(), 'temp-arff.csv')\n",
    "    _WEKA_PATH = join(os.getcwd(), 'weka-3-9-3', 'weka.jar')\n",
    "    _PARAMETERS = 'weka.core.converters.CSVSaver'\n",
    "    command = 'java -Xmx{}g -cp {}'.format(memory, _WEKA_PATH)\n",
    "    command += ' {}'.format(_PARAMETERS)\n",
    "    command += ' -i {}'.format(arffFile)\n",
    "    command += ' -o {}'.format(csv)\n",
    "    #call([command], shell=True)\n",
    "    os.system(command)\n",
    "    dataframe = pandas.read_csv(csv)\n",
    "    if threshold == 'TNO': return(dataframe)\n",
    "    else: return(group_replace(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:11.007832Z",
     "start_time": "2020-12-19T06:43:10.896103Z"
    },
    "code_folding": [
     0,
     15,
     47,
     72,
     97,
     117,
     140,
     159,
     178,
     197,
     216,
     236
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def feature_selection(frames, threshold, featset_dir):\n",
    "    # Filter: variance, correlation(pearson's), chi-square\n",
    "    # wrapper: recurssive feature elimination(RFE), mlxtend.SequentialFeatureSelector([fwd, bwd, bid]) and mlxtend.ExhaustiveFeatureSelector()\n",
    "    # embeded or hybrid: log.reg.(LASSO Regularization[L1 penality]) random forest, lightgbm, lasso, weka([fwd, bwd, bid])\n",
    "    selected_frames = {}\n",
    "    for name, frame in frames.items():\n",
    "        # Define X and y variables\n",
    "        X = frame.drop('class', 1)\n",
    "        y = frame['class']\n",
    "        # X = frame[frame.columns[:-1]]\n",
    "        # y = frame[frame.columns[-1]]\n",
    "\n",
    "        # Extract feature names\n",
    "        feature_name = X.columns.tolist()\n",
    "\n",
    "        def variance():\n",
    "            # filter method\n",
    "            '''\n",
    "            As an example, suppose that we have a dataset with boolean features, \n",
    "            and we want to remove all features that are either one or zero (on or off) \n",
    "            in more than 80% of the samples. Boolean features are Bernoulli random variables, \n",
    "            and the variance of such variables is given by \n",
    "            Var[X] = p(1-p)\n",
    "            so we can select using the threshold .8 * (1 - .8)\n",
    "            '''\n",
    "            try:\n",
    "                # Create and fit selector\n",
    "                variance_filter = VarianceThreshold(threshold=(0.8*(1-0.8)))  #threshold=0\n",
    "                features = variance_filter.fit_transform(X)\n",
    "                # Get columns to keep\n",
    "                variance_support = variance_filter.get_support()\n",
    "                variance_feature = X.loc[:, variance_support].columns.tolist()\n",
    "\n",
    "                frame_name = ('|  |_ For {} descriptor set Variance'\n",
    "                              ' selected {} descriptors'.format(name, len(variance_feature)))\n",
    "\n",
    "                if len(variance_feature) > 0:\n",
    "                    # Create new dataframe with only desired columns\n",
    "                    variance_features = frame[variance_feature]\n",
    "                    variance_frame = pandas.concat([variance_features, y], axis=1)\n",
    "                    print(frame_name)\n",
    "                    variance_frame.to_csv('{}.csv'.format(join(featset_dir, name+'_Var')), index=False)\n",
    "                    return(variance_frame)\n",
    "                else: print(frame_name)\n",
    "            except ValueError:\n",
    "                print('|  |_ For {} descriptor set Variance selected {} descriptors'.format(name, 0))\n",
    "\n",
    "        def correl():\n",
    "            # filter method\n",
    "            # Get correlation coefficients of all columns\n",
    "            cor = X.corr()\n",
    "            columns = numpy.full((cor.shape[0], ), True, dtype=bool)\n",
    "            for i in range(cor.shape[0]):\n",
    "                for j in range(i + 1, cor.shape[0]):\n",
    "                    if cor.iloc[i, j] >= 0.75:\n",
    "                        if columns[j]:\n",
    "                            columns[j] = False\n",
    "            # Get columns to keep i.e below a thershold of 0.75 pearson correlation\n",
    "            cor_feature = X.columns[columns]\n",
    "\n",
    "            frame_name = ('|  |_ For {} descriptor set Correlation'\n",
    "                          ' selected {} descriptors'.format(name, len(cor_feature)))\n",
    "\n",
    "            if len(cor_feature) > 0:\n",
    "                # Create new dataframe with only desired columns\n",
    "                cor_features = X[cor_feature]\n",
    "                cor_frame = pandas.concat([cor_features, y], axis=1)\n",
    "                print(frame_name)\n",
    "                cor_frame.to_csv('{}.csv'.format(join(featset_dir, name+'_Cor')), index=False)\n",
    "                return(cor_frame)\n",
    "            else: print(frame_name)\n",
    "\n",
    "        def chi_square():\n",
    "            # filter method\n",
    "            # Normalize the X values\n",
    "            X_norm = MinMaxScaler().fit_transform(X)\n",
    "            # Create and fit selector\n",
    "            if X_norm.shape[1] <10:\n",
    "                chi_selector = SelectKBest(chi2, k='all')\n",
    "            else:\n",
    "                chi_selector = SelectKBest(chi2)\n",
    "            chi_selector.fit(X_norm, y)\n",
    "            # Get columns to keep\n",
    "            chi_support = chi_selector.get_support()\n",
    "            chi_feature = X.loc[:, chi_support].columns.tolist()\n",
    "\n",
    "            frame_name = ('|  |_ For {} descriptor set Chi-Square'\n",
    "                          ' selected {} descriptors'.format(name, len(chi_feature)))\n",
    "            if len(chi_feature) > 0:\n",
    "                # Create new dataframe with only desired columns\n",
    "                chi_features = frame[chi_feature]\n",
    "                chi_frame = pandas.concat([chi_features, y], axis=1)\n",
    "                print(frame_name)\n",
    "                chi_frame.to_csv('{}.csv'.format(join(featset_dir, name+'_Chi')), index=False)\n",
    "                return(chi_frame)\n",
    "            else: print(frame_name)\n",
    "\n",
    "        def rfe():\n",
    "            # wrapper method\n",
    "            # Create and fit selector\n",
    "            rfe_selector = RFE(estimator)#DecisionTreeClassifier RandomForestClassifier(n_jobs=-1) LogisticRegression(n_jobs=-1)\n",
    "            rfe_selector.fit(X, y)\n",
    "            # Get columns to keep\n",
    "            rfe_support = rfe_selector.get_support()\n",
    "            rfe_feature = X.loc[:, rfe_support].columns.tolist()\n",
    "\n",
    "            frame_name = ('|  |_ For {} descriptor set Recursive Feature Elimination'\n",
    "                          ' selected {} descriptors'.format(name, len(rfe_feature)))\n",
    "            if len(rfe_feature) > 0:\n",
    "                # Create new dataframe with only desired columns\n",
    "                rfe_features = frame[rfe_feature]\n",
    "                rfe_frame = pandas.concat([rfe_features, y], axis=1)\n",
    "                print(frame_name)\n",
    "                rfe_frame.to_csv('{}.csv'.format(join(featset_dir, name+'_Rfe')), index=False)\n",
    "                return(rfe_frame)\n",
    "            else: print(frame_name)\n",
    "\n",
    "        def logreg():\n",
    "            # embeded method\n",
    "            # Create and fit selector\n",
    "            lr_selector = SelectFromModel(LogisticRegression(penalty='l1'\n",
    "                                                             , random_state=369\n",
    "                                                             , solver='saga'\n",
    "                                                             , n_jobs=-1))\n",
    "            lr_selector.fit(X, y)\n",
    "            # Get columns to keep\n",
    "            lr_support = lr_selector.get_support()\n",
    "            lr_feature = X.loc[:, lr_support].columns.tolist()\n",
    "\n",
    "            frame_name = ('|  |_ For {} descriptor set Log.Reg.-L1'\n",
    "                          ' selected {} descriptors'.format(name, len(lr_feature)))\n",
    "            if len(lr_feature) > 0:\n",
    "                # Create new dataframe with only desired columns\n",
    "                lr_features = frame[lr_feature]\n",
    "                lr_frame = pandas.concat([lr_features, y], axis=1)\n",
    "                print(frame_name)\n",
    "                lr_frame.to_csv('{}.csv'.format(join(featset_dir, name+'_Lor')), index=False)\n",
    "                return(lr_frame)\n",
    "            else: print(frame_name)\n",
    "\n",
    "        def rf():\n",
    "            # embeded method\n",
    "            # Create and fit selector\n",
    "            rf_selector = SelectFromModel(RandomForestClassifier(n_jobs=-1))\n",
    "            rf_selector.fit(X, y)\n",
    "            # Get columns to keep\n",
    "            rf_support = rf_selector.get_support()\n",
    "            rf_feature = X.loc[:, rf_support].columns.tolist()\n",
    "            frame_name = ('|  |_ For {} descriptor set Random Forest'\n",
    "                          ' selected {} descriptors'.format(name, len(rf_feature)))\n",
    "            if len(rf_feature) > 0:\n",
    "                # Create new dataframe with only desired columns\n",
    "                rf_features = frame[rf_feature]\n",
    "                rf_frame = pandas.concat([rf_features, y], axis=1)\n",
    "                print(frame_name)\n",
    "                rf_frame.to_csv('{}.csv'.format(join(featset_dir, name+'_Rf')), index=False)\n",
    "                return(rf_frame)\n",
    "            else: print(frame_name)\n",
    "        \n",
    "        def rfr():\n",
    "            # embeded method\n",
    "            # Create and fit selector\n",
    "            rfr_selector = SelectFromModel(RandomForestRegressor(n_jobs=-1))\n",
    "            rfr_selector.fit(X, y)\n",
    "            # Get columns to keep\n",
    "            rfr_support = rfr_selector.get_support()\n",
    "            rfr_feature = X.loc[:, rfr_support].columns.tolist()\n",
    "            frame_name = ('|  |_ For {} descriptor set Random Forest'\n",
    "                          ' selected {} descriptors'.format(name, len(rfr_feature)))\n",
    "            if len(rfr_feature) > 0:\n",
    "                # Create new dataframe with only desired columns\n",
    "                rfr_features = frame[rfr_feature]\n",
    "                rfr_frame = pandas.concat([rfr_features, y], axis=1)\n",
    "                print(frame_name)\n",
    "                rfr_frame.to_csv('{}.csv'.format(join(featset_dir, name+'_rfr')), index=False)\n",
    "                return(rfr_frame)\n",
    "            else: print(frame_name)\n",
    "\n",
    "        def lgb():\n",
    "            # embeded method\n",
    "            # Create and fit selector\n",
    "            lgb_selector = SelectFromModel(LGBMClassifier(n_jobs=-1))\n",
    "            lgb_selector.fit(X.astype(float), y)\n",
    "            # Get columns to keep\n",
    "            lgb_support = lgb_selector.get_support()\n",
    "            lgb_feature = X.loc[:, lgb_support].columns.tolist()\n",
    "            frame_name = ('|  |_ For {} descriptor set LightGBM'\n",
    "                          ' selected {} descriptors'.format(name, len(lgb_feature)))\n",
    "            if len(lgb_feature) > 0:\n",
    "                # Create new dataframe with only desired columns\n",
    "                lgb_features = frame[lgb_feature]\n",
    "                lgb_frame = pandas.concat([lgb_features, y], axis=1)\n",
    "                print(frame_name)\n",
    "                lgb_frame.to_csv('{}.csv'.format(join(featset_dir, name+'_Lgb')), index=False)\n",
    "                return(lgb_frame)\n",
    "            else: print(frame_name)\n",
    "\n",
    "        def lasso():\n",
    "            # embeded method\n",
    "            # Create and fit selector\n",
    "            lasso_selector = SelectFromModel(Lasso())\n",
    "            lasso_selector.fit(X, y)\n",
    "            # Get columns to keep\n",
    "            lasso_support = lasso_selector.get_support()\n",
    "            lasso_feature = X.loc[:, lasso_support].columns.tolist()\n",
    "            frame_name = ('|  |_ For {} descriptor set Lasso'\n",
    "                          ' selected {} descriptors'.format(name, len(lasso_feature)))\n",
    "            if len(lasso_feature) > 0:\n",
    "                # Create new dataframe with only desired columns\n",
    "                lasso_features = frame[lasso_feature]\n",
    "                lasso_frame = pandas.concat([lasso_features, y], axis=1)\n",
    "                print(frame_name)\n",
    "                lasso_frame.to_csv('{}.csv'.format(join(featset_dir, name+'_Lasso')), index=False)\n",
    "                return(lasso_frame)\n",
    "            else: print(frame_name)\n",
    "        \n",
    "        def rfecv(estimator):\n",
    "            # wrapper method\n",
    "            # Create and fit selector\n",
    "            rfecv_selector = RFECV(estimator, n_jobs=-1)\n",
    "            rfecv_selector.fit(X, y)\n",
    "            # Get columns to keep\n",
    "            rfecv_support = rfecv_selector.get_support()\n",
    "            rfecv_feature = X.loc[:, rfecv_support].columns.tolist()\n",
    "\n",
    "            frame_name = ('|  |_ For {} descriptor set Recursive Feature Elimination CV'\n",
    "                          ' selected {} descriptors'.format(name, len(rfecv_feature)))\n",
    "            if len(rfecv_feature) > 0:\n",
    "                # Create new dataframe with only desired columns\n",
    "                rfecv_features = frame[rfecv_feature]\n",
    "                rfecv_frame = pandas.concat([rfecv_features, y], axis=1)\n",
    "                print(frame_name)\n",
    "                rfecv_frame.to_csv('{}.csv'.format(join(featset_dir, name+'_Rfecv')), index=False)\n",
    "                return(rfecv_frame)\n",
    "            else: print(frame_name)\n",
    "\n",
    "        def wekadescSelect():\n",
    "            # total memory in bytes are converted to gigabytes and 70% is going to provide for weka\n",
    "            memory = round(((virtual_memory().total)/1024**3)*0.7)\n",
    "            _WEKA_PATH = join(os.getcwd(), 'weka-3-9-3', 'weka.jar')\n",
    "            selector = \"weka.filters.supervised.attribute.AttributeSelection\"\n",
    "            evaluator = '-E \"weka.attributeSelection.CfsSubsetEval -P 1 -E 1\"'  # evaluator method\n",
    "            search = '-S \"weka.attributeSelection.BestFirst -D'  #search method\n",
    "            command = 'java -Xmx{}g -cp {}'.format(memory, _WEKA_PATH)\n",
    "            command += ' {}'.format(selector)\n",
    "            command += ' {}'.format(evaluator)\n",
    "            command += ' {}'.format(search)\n",
    "            desc_frames = {}\n",
    "            frame_names = []\n",
    "            arff = dataframetoarff(frame, threshold)\n",
    "            desc = join(os.getcwd(), 'desc.arff')\n",
    "            directions = ['fwd', 'bid']  # 0,1,2\n",
    "            for direc in range(len(directions)):\n",
    "                option = ' {} -N 5\"'.format(direc+1)\n",
    "                inp = ' -i {}'.format(arff)\n",
    "                outp = ' -o {}'.format(desc)\n",
    "                proc = command + option + inp + outp\n",
    "                #call([proc], shell=True)\n",
    "                os.system(proc)\n",
    "                descframe = arfftodataframe(desc, threshold)\n",
    "                desc_frames[name + '_' + directions[direc]]=descframe\n",
    "                descframe.to_csv('{}.csv'.format(join(featset_dir, name+'_'+directions[direc])), index=False)\n",
    "                proc = ''\n",
    "            # check for similar sets in these three feature reduction sets\n",
    "            if list(list(desc_frames.values())[0].columns) == list(list(desc_frames.values())[1].columns):\n",
    "                desc_frames.pop(list(desc_frames.keys())[1], None)\n",
    "                frame_name = ('|  |_ For {} descriptor set weka-cfs-Bestfirst'\n",
    "                              '-{} selected {} descriptors'.format(name\n",
    "                                                                   , list(desc_frames)[0].split('_')[-1]\n",
    "                                                                   , descframe.shape[1]-1))\n",
    "                print(frame_name)\n",
    "                print('|  |  |_ fwd and bid are same. Deleting bid')\n",
    "                return(desc_frames)\n",
    "            else:\n",
    "                for key in desc_frames.keys():\n",
    "                    frame_name = ('|  |_ For {} descriptor set weka-cfs-Bestfirst'\n",
    "                                  '-{} selected {} descriptors'.format(name, key.split('_')[-1], descframe.shape[1]-1))\n",
    "                    print(frame_name)\n",
    "                return(desc_frames)\n",
    "\n",
    "                \n",
    "        if '_nopvalue' in name or len(feature_name) <= 2:\n",
    "            frame = group_replace(frame)\n",
    "            selected_frames[name +'-noFeatSel'] = frame\n",
    "            frame.to_csv('{}.csv'.format(join(featset_dir, name+'-noFeatSel')), index=False)\n",
    "            print('|  |_ For {} descriptor set NO METHOD'\n",
    "                  ' selected {} descriptors'.format(name, frame.shape[1]-1))\n",
    "        else:\n",
    "            if threshold == 'TNO': # for continous variables\n",
    "                desc_variance = variance()\n",
    "                if desc_variance is not None:\n",
    "                    selected_frames[name +'_Var']=desc_variance\n",
    "\n",
    "                # correl giving a lot of features which will lead to overfitting\n",
    "                #desc_correl = correl()\n",
    "                #selected_frames[name +'_Cor']=desc_correl\n",
    "\n",
    "                #desc_lasso = lasso()\n",
    "                #if desc_lasso is not None:\n",
    "                #    selected_frames[name +'_Lasso']=desc_lasso\n",
    "                \n",
    "                #estimator = RandomForestRegressor(n_jobs=-1)\n",
    "                #desc_rfecv = rfecv(estimator)\n",
    "                #if desc_rfecv is not None:\n",
    "                #    selected_frames[name +'_Rfecv']=desc_rfecv\n",
    "                \n",
    "                desc_rf = rfr()\n",
    "                if desc_rf is not None:\n",
    "                    selected_frames[name +'_Rf']=desc_rf\n",
    "\n",
    "                desc_weka = wekadescSelect()\n",
    "                if desc_weka is not None:\n",
    "                    selected_frames.update(desc_weka)\n",
    "            else: # for binary or multi class variables\n",
    "                desc_variance = variance()\n",
    "                if desc_variance is not None:\n",
    "                    selected_frames[name +'_Var']=desc_variance\n",
    "\n",
    "                # correl giving a lot of features which will lead to overfitting\n",
    "                #desc_correl = correl()\n",
    "                #selected_frames[name +'_Cor']=desc_correl\n",
    "\n",
    "                # only defined number of features will be selected. Need auto feature selection method. Not manually defined.\n",
    "                #desc_chisquare = chi_square()\n",
    "                #selected_frames[name +'_Chi']=desc_chisquare\n",
    "\n",
    "                #desc_rfe = rfe()\n",
    "                #selected_frames[name +'_Rfe']=desc_rfe\n",
    "\n",
    "                desc_logreg = logreg()\n",
    "                if desc_logreg is not None:\n",
    "                    selected_frames[name +'_Lor']=desc_logreg\n",
    "                \n",
    "                desc_rf = rf()\n",
    "                if desc_rf is not None:\n",
    "                    selected_frames[name +'_Rf']=desc_rf\n",
    "                \n",
    "                # LightGBMError: Do not support special JSON characters in feature name. -- have to figure out\n",
    "                # Error is only with FingerprintMol\n",
    "                #desc_lgb = lgb()\n",
    "                #selected_frames[name +'_Lgb']=desc_lgb\n",
    "                \n",
    "                #desc_lasso = lasso()\n",
    "                #if desc_lasso is not None:\n",
    "                #    selected_frames[name +'_Lasso']=desc_lasso\n",
    "                \n",
    "                #estimator = RandomForestClassifier(n_jobs=-1)\n",
    "                #desc_rfecv = rfecv(estimator)\n",
    "                #if desc_rfecv is not None:\n",
    "                #    selected_frames[name +'_Rfecv']=desc_rfecv\n",
    "\n",
    "                desc_weka = wekadescSelect()\n",
    "                if desc_weka is not None:\n",
    "                    selected_frames.update(desc_weka)\n",
    "    return(selected_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:11.035427Z",
     "start_time": "2020-12-19T06:43:11.010725Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_models(threshold, frame, featset, name, reg_algo, clas_algo, fix=False, imbl_method=None):\n",
    "    exp_name = '{}_{}'.format(featset, name)\n",
    "    #print('{}, {}, {}, {}, {}'.format(threshold, frame, exp_name, fix, imbl_method))\n",
    "    if threshold == 'TNO':\n",
    "        model_conf = regression.setup(data=frame, target='class', session_id=99\n",
    "                                      , log_experiment=True, experiment_name=exp_name\n",
    "                                      , silent=True, verbose=False)#, use_gpu=True)\n",
    "        #['lasso', 'ridge', 'en', 'lar'\n",
    "        #, 'llar', 'omp', 'br', 'ard'\n",
    "        #, 'par', 'ransac', 'tr', 'huber'\n",
    "        #, 'kr', 'knn', 'dt', 'et'\n",
    "        #, 'ada', 'gbr', 'mlp', 'xgboost'\n",
    "        #, 'lightgbm', 'catboost']\n",
    "        models = regression.compare_models(exclude=reg_algo, verbose=False)\n",
    "        results = regression.pull()\n",
    "    else:\n",
    "        model_conf = classification.setup(data=frame, target='class', fix_imbalance=fix\n",
    "                                          , fix_imbalance_method=imbl_method, session_id=99\n",
    "                                          , log_experiment=True, experiment_name=exp_name\n",
    "                                          , silent=True, verbose=False)#, use_gpu=True)\n",
    "        # return best model\n",
    "        # cannot use include and exclude together..\n",
    "        #verbose: bool, default = True. Score grid is not printed when verbose is set to False.\n",
    "        #['knn', 'nb', 'dt', 'rbfsvm'\n",
    "        #, 'gpc', 'mlp', 'ridge', 'qda'\n",
    "        #, 'ada', 'gbc' , 'lda', 'et', 'svm'\n",
    "        #, 'xgboost', 'lightgbm', 'catboost']\n",
    "        models = classification.compare_models(exclude=clas_algo, verbose=False)\n",
    "        results = classification.pull()\n",
    "    name = exp_name.split('_')[-1]\n",
    "    #if not results.empty:\n",
    "    results['sampling_method'] = name\n",
    "    #results['threshold'] = threshold\n",
    "    results['thresh_std_feature_set'] = featset\n",
    "    results['features_count'] = frame.shape[1]-1\n",
    "    #results['features'] = list(frame.columns)\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:11.143552Z",
     "start_time": "2020-12-19T06:43:11.041858Z"
    },
    "code_folding": [
     9,
     12,
     15,
     77,
     88,
     91,
     94,
     96
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ml_workflow(std_records, target_id, targ_dir, cutoffs, thresholds, reg_algo, clas_algo):\n",
    "    data_end_time = time.time()\n",
    "    # get the sdf filename\n",
    "    sd_filename = smi_to_sdf(std_records, target_id, targ_dir)\n",
    "    # get descriptor sets\n",
    "    print('|_ Features generation was initiated')\n",
    "    desc_sets = calc_desc_fp(sd_filename)\n",
    "    desc_time = time.time()\n",
    "    print('|_ Features generation was completed')\n",
    "    if (desc_time-data_end_time) < 60:\n",
    "        print('|_ {} sec for descriptors and fingerprints'\n",
    "              ' calculation'.format(round((desc_time-data_end_time), 2)))\n",
    "    elif ((desc_time-data_end_time)/60) < 60:\n",
    "        print('|_ {} min for descriptors and fingerprints'\n",
    "              ' calculation'.format(round((desc_time-data_end_time)/60, 2)))\n",
    "    else: print('|_ {} hrs for descriptors and fingerprints'\n",
    "                ' calculation'.format(round((desc_time-data_end_time)/3600, 2)))\n",
    "    target_model_results = pandas.DataFrame()\n",
    "    ngboost = NGBClassifier()\n",
    "    #thresholds = ['TNO', 'TMC', 'T01K', 'T1K', 'T10K'] #'T01K', 'T1K', 'T10K', 'TMC', 'TNO'\n",
    "    for threshold in thresholds:\n",
    "        train_frames = {}\n",
    "        test_frames = {}\n",
    "        single_class = ''\n",
    "        # empty dataframe for appending the threshold_results\n",
    "        threshold_results = pandas.DataFrame()\n",
    "        print('|_ For threshold {}, Feature transformation'\n",
    "              ' and pvalue selection was initiated'.format(threshold))\n",
    "        # get the feat time\n",
    "        feat_trans_time0 = time.time()\n",
    "        drop_cols = list(std_records.columns)\n",
    "        for set_name, desc_frame in desc_sets.items():\n",
    "            dataframe = get_class(std_records, desc_frame, threshold, cutoffs)\n",
    "            if len(dataframe.groupby('class').groups.keys()) > 1:\n",
    "                train_desc, test_desc = get_train_test_sets(dataframe, threshold, drop_cols)\n",
    "                transformed_sets = data_transformation(set_name, train_desc, threshold)\n",
    "                for trans_name, trans_frame in transformed_sets.items():\n",
    "                    #trans_list = trans_frame.iloc[:, [0, 10, 30, 50, -1]] \n",
    "                    #print('{}:\\n{}'.format(trans_name, trans_list))\n",
    "                    if 'Fingerprint' in trans_name:\n",
    "                        pvalue_frame = pvalue_calc(trans_frame, threshold)\n",
    "                        train_frames[trans_name]=pvalue_frame\n",
    "                        print('|  |_ For set:{}, {}/{} Selected_Features(pvalue)/Total_Features'.format(trans_name, pvalue_frame.shape[1]-1, train_desc.shape[1]-1))\n",
    "                        name = '{}_nopvalue'.format(trans_name)\n",
    "                        train_frames[name]=trans_frame\n",
    "                        print('|  |_ For set:{}, {}/{} Selected_Features(pvalue)/Total_Features'.format(name, trans_frame.shape[1]-1, train_desc.shape[1]-1))\n",
    "                    else:\n",
    "                        pvalue_frame = pvalue_calc(trans_frame, threshold)\n",
    "                        train_frames[trans_name]=pvalue_frame\n",
    "                        print('|  |_ For set:{}, {}/{} Selected_Features(pvalue)/Total_Features'.format(trans_name, pvalue_frame.shape[1]-1, train_desc.shape[1]-1))\n",
    "            \n",
    "            else:\n",
    "                single_class = dataframe['class'].unique().tolist()\n",
    "                print('|  |_Found only single class: Class {}. Skipping feature transformation and pvalue selection.'.format(single_class[0]))\n",
    "                break\n",
    "        # get the feat time\n",
    "        feat_trans_time1 = time.time()\n",
    "        print('|_ For threshold: {}, feature transformation'\n",
    "              ' and pvalue selection was completed'.format(threshold))\n",
    "        # processing time\n",
    "        if (feat_trans_time1-feat_trans_time0) < 60:\n",
    "            print('|_ {} sec for feature transformation'\n",
    "                  ' and pvalue selection'.format(round((feat_trans_time1-feat_trans_time0), 2)))\n",
    "        elif ((feat_trans_time1-feat_trans_time0)/60) < 60:\n",
    "            print('|_ {} min for feature transformation'\n",
    "                  ' and pvalue selection'.format(round((feat_trans_time1-feat_trans_time0)/60, 2)))\n",
    "        else: print('|_ {} hrs for feature transformation'\n",
    "                    ' and pvalue based feature selection'.format(round((feat_trans_time1\n",
    "                                                                        -feat_trans_time0)/3600, 2)))\n",
    "        print('|_ For {}, a total of {} feature sets are transformed'\n",
    "              ' and are ready for feature selection'.format(threshold, len(train_frames)))\n",
    "        print('|_ For threshold: {}, feature selection was initiated'.format(threshold))\n",
    "\n",
    "        featset_dir = join(targ_dir, '{}_{}'.format('feature-sets',threshold))\n",
    "        os.mkdir(featset_dir)\n",
    "        if not train_frames:# if train_frames are empty\n",
    "            print('|  |_Found only single class: Class {}. Skipping feature selection.'.format(single_class[0]))\n",
    "            print('|_Found only single class: Class {}. Skipping training the models.'.format(single_class[0]))\n",
    "        else:\n",
    "            # get the feat time\n",
    "            feat_sel_time0 = time.time()\n",
    "            # get the selected features\n",
    "            feats_selected = feature_selection(train_frames, threshold, featset_dir)\n",
    "            # get the feat time\n",
    "            feat_sel_time1 = time.time()\n",
    "            print('|_ For threshold: {}, feature selection was completed'.format(threshold))\n",
    "            if (feat_sel_time1-feat_sel_time0) < 60:\n",
    "                print('|_ {} sec for feature selection'.format(round((feat_sel_time1\n",
    "                                                                      -feat_sel_time0), 2)))\n",
    "            elif ((feat_sel_time1-feat_sel_time0)/60) < 60:\n",
    "                print('|_ {} min for feature selection'.format(round((feat_sel_time1\n",
    "                                                                      -feat_sel_time0)/60, 2)))\n",
    "            else: print('|_ {} hrs for feature selection'.format(round((feat_sel_time1\n",
    "                                                                        -feat_sel_time0)/3600, 2)))\n",
    "            print('|_ For {}, a total of {} feature sets'\n",
    "                  ' are ready for model generation'.format(threshold, len(feats_selected)))#count))\n",
    "\n",
    "            # models\n",
    "            # do model training and get training set results\n",
    "            model_time0 = time.time()\n",
    "            for featset, frame in feats_selected.items():\n",
    "                #print('printing frame name: {} and shape: {}'.format(featset, frame.shape))\n",
    "                try:\n",
    "                    if threshold == 'TNO':\n",
    "                        name = 'None'\n",
    "                        results = build_models(threshold, frame, featset, name, reg_algo, clas_algo)\n",
    "                        #print(results)\n",
    "                        threshold_results = pandas.concat([threshold_results, results], ignore_index=True)\n",
    "                        #threshold_results.drop('TT (Sec)', axis=1, inplace=True)\n",
    "                        print('Results for {}: model results\\n {}'.format(featset, threshold_results))\n",
    "                    else:\n",
    "                        sample_size = frame.groupby('class').size().values[0]# sample size of the minor class\n",
    "                        if sample_size <=5: neighbors = sample_size-1\n",
    "                        else: neighbors = 5\n",
    "                        if sample_size < 2 :\n",
    "                            name = 'None'\n",
    "                            results = build_models(threshold, frame, featset, name, reg_algo, clas_algo)\n",
    "                            threshold_results = pandas.concat([threshold_results, results], ignore_index=True)\n",
    "                            #threshold_results.drop('TT (Sec)', axis=1, inplace=True)\n",
    "                            print('Results for {}: model results\\n {}'.format(featset, threshold_results))\n",
    "                        else:\n",
    "                            # sampling_strategy= 'not majority': resample all classes but the majority class;\n",
    "                            imbl_dict = {'None':None\n",
    "                                         , 'SMOTE':SMOTE(random_state=369\n",
    "                                                         , sampling_strategy='not majority'\n",
    "                                                         , k_neighbors=neighbors, n_jobs=14)\n",
    "                                         , 'SVMSMOTE':SVMSMOTE(random_state=369\n",
    "                                                               , sampling_strategy='not majority'\n",
    "                                                               , k_neighbors=neighbors, n_jobs=14)\n",
    "                                         , 'BLSMOTE':BorderlineSMOTE(random_state=369\n",
    "                                                                     , sampling_strategy='not majority'\n",
    "                                                                     , k_neighbors=neighbors, n_jobs=14)\n",
    "                                         , 'ADASYN':ADASYN(random_state=369\n",
    "                                                           , sampling_strategy='not majority'\n",
    "                                                           , n_neighbors=neighbors, n_jobs=14)}\n",
    "                                         #, 'KMeansSMOTE':KMeansSMOTE(random_state=369\n",
    "                                         #                            , sampling_strategy='not majority'\n",
    "                                         #                            , k_neighbors=neighbors, n_jobs=14)\n",
    "                            for name, imbl_method in imbl_dict.items():\n",
    "                                if name == 'None': fix=False\n",
    "                                else: fix=True\n",
    "                                results = build_models(threshold, frame, featset, name, reg_algo, clas_algo, fix, imbl_method)\n",
    "                                threshold_results = pandas.concat([threshold_results, results]\n",
    "                                                                  , ignore_index=True)\n",
    "                                #threshold_results.drop('TT (Sec)', axis=1, inplace=True)\n",
    "                            print('Results for {}: model results\\n {}'.format(featset, threshold_results))\n",
    "                except RuntimeError as rte:\n",
    "                    print('RuntimeError for {} with shape {}'\n",
    "                          '\\nError: {}'.format(featset, frame.shape, rte))\n",
    "                    print(frame['class'])\n",
    "                    pass\n",
    "                except ValueError as ve:\n",
    "                    print('ValueError for {} with shape {}'\n",
    "                          '\\nError: {}'.format(featset, frame.shape, ve))\n",
    "                    print(frame['class'])\n",
    "                    pass\n",
    "                #except:\n",
    "                #    # handle all other exceptions\n",
    "                #    pass\n",
    "\n",
    "            if threshold == 'TNO':\n",
    "                threshold_results.sort_values('MAE', axis=0, ascending=True, inplace=True) # MAE\n",
    "                threshold_results.to_csv('{}_{}_training_set_results.csv'.format(join(targ_dir, target_id)\n",
    "                                                                                 ,threshold), index=False)\n",
    "            else:\n",
    "                threshold_results.sort_values(['MCC', 'Accuracy'], axis=0\n",
    "                                              , ascending = (False, False), inplace=True)\n",
    "                threshold_results.to_csv('{}_{}_training_set_results.csv'.format(join(targ_dir, target_id)\n",
    "                                                                                 , threshold), index=False)\n",
    "            print(threshold_results)\n",
    "            display(threshold_results)\n",
    "            model_time1 = time.time()\n",
    "            print('For threshold: {},'\n",
    "                  ' Total Models generated: {}'.format(threshold, threshold_results.shape[0]))\n",
    "            # processing time\n",
    "            if (model_time1-model_time0) < 60:\n",
    "                print('|_ {} sec for training the models'.format(round((model_time1-model_time0), 2)))\n",
    "            elif ((model_time1-model_time0)/60) < 60:\n",
    "                print('|_ {} min for training the models'.format(round((model_time1-model_time0)/60, 2)))\n",
    "            else: print('|_ {} hrs for training the models'.format(round((model_time1\n",
    "                                                                          -model_time0)/3600, 2)))\n",
    "            target_model_results = pandas.concat([target_model_results, threshold_results]\n",
    "                                                 , ignore_index=True)\n",
    "    # get the end time\n",
    "    end_time = time.time()\n",
    "    print('For Target: {}, Total Models generated: {}'.format(target_id, target_model_results.shape[0]))\n",
    "    if (end_time-start_time) < 60:\n",
    "        print('|_ {} sec for data to models generation'.format(round((end_time-start_time), 2)))\n",
    "    elif ((end_time-start_time)/60) < 60:\n",
    "        print('|_ {} min for data to models generation'.format(round((end_time-start_time)/60, 2)))\n",
    "    else: print('|_ {} hrs for data to models generation'.format(round((end_time-start_time)/3600, 2)))\n",
    "    target_model_results.to_csv('{}_training_set_results.csv'.format(join(targ_dir, target_id))\n",
    "                                , index=False)\n",
    "    print('\\n\\n\\n')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:11.192458Z",
     "start_time": "2020-12-19T06:43:11.147941Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_thresholds():\n",
    "    cutoffs = easygui.multchoicebox(msg='Choose atleast one from given thresholds in Î¼M (microMolar):'\n",
    "                                   , title='Threshold for model building'\n",
    "                                   , choices=[0.1, 1, 10, 30]\n",
    "                                   , preselect=[2])\n",
    "    if not cutoffs:\n",
    "        return(cutoffs, ['TNO'])\n",
    "    else:\n",
    "        if len(cutoffs)>1:\n",
    "            thresholds = ['T{}'.format(c) for c in cutoffs]\n",
    "            thresholds.extend(['TMC', 'TNO'])\n",
    "        else:\n",
    "            thresholds = ['T{}'.format(''.join(cutoffs)),'TNO']\n",
    "        return(cutoffs, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T06:43:11.231931Z",
     "start_time": "2020-12-19T06:43:11.198608Z"
    },
    "code_folding": [
     0,
     50
    ]
   },
   "outputs": [],
   "source": [
    "def set_aglorithms(threshold):\n",
    "    if threshold == 'TNO':\n",
    "        algo_list = ['AdaBoost Regressor','Automatic Relevance Determination'\n",
    "                     ,'Bayesian Ridge', 'CatBoost Regressor'\n",
    "                     , 'Decision Tree Regressor', 'Elastic Net'\n",
    "                     , 'Extra Trees Regressor', 'Gradient Boosting Regressor'\n",
    "                     , 'Huber Regressor', 'K Neighbors Regressor'\n",
    "                     , 'Kernel Ridge', 'Least Angle Regression'\n",
    "                     , 'Lasso Regression', 'Light Gradient Boosting Machine'\n",
    "                     , 'Lasso Least Angle Regression', 'Linear Regression'\n",
    "                     , 'MLP Regressor', 'Orthogonal Matching Pursuit'\n",
    "                     , 'Passive Aggressive Regressor', 'Random Sample Consensus'\n",
    "                     , 'Random Forest Regressor', 'Ridge Regression'\n",
    "                     , 'Support Vector Regression', 'TheilSen Regressor'\n",
    "                     , 'Extreme Gradient Boosting']\n",
    "        algo_dict = {'ada' : 'AdaBoost Regressor', 'ard' : 'Automatic Relevance Determination'\n",
    "                     , 'br' : 'Bayesian Ridge', 'catboost' : 'CatBoost Regressor'\n",
    "                     , 'dt' : 'Decision Tree Regressor', 'en' : 'Elastic Net'\n",
    "                     , 'et' : 'Extra Trees Regressor', 'gbr' : 'Gradient Boosting Regressor'\n",
    "                     , 'huber' : 'Huber Regressor', 'knn' : 'K Neighbors Regressor'\n",
    "                     , 'kr' : 'Kernel Ridge', 'lar' : 'Least Angle Regression'\n",
    "                     , 'lasso' : 'Lasso Regression', 'lightgbm' : 'Light Gradient Boosting Machine'\n",
    "                     , 'llar' : 'Lasso Least Angle Regression', 'lr' : 'Linear Regression'\n",
    "                     , 'mlp' : 'MLP Regressor', 'omp' : 'Orthogonal Matching Pursuit'\n",
    "                     , 'par' : 'Passive Aggressive Regressor', 'ransac' : 'Random Sample Consensus'\n",
    "                     , 'rf' : 'Random Forest Regressor', 'ridge' : 'Ridge Regression'\n",
    "                     , 'svm' : 'Support Vector Regression', 'tr' : 'TheilSen Regressor'\n",
    "                     , 'xgboost' : 'Extreme Gradient Boosting'}\n",
    "    else:\n",
    "        algo_list = ['Ada Boost Classifier', 'CatBoost Classifier'\n",
    "                     , 'Decision Tree Classifier', 'Extra Trees Classifier'\n",
    "                     , 'Gradient Boosting Classifier', 'Gaussian Process Classifier'\n",
    "                     , 'K Neighbors Classifier', 'Linear Discriminant Analysis'\n",
    "                     , 'Light Gradient Boosting Machine', 'Logistic Regression'\n",
    "                     , 'MLP Classifier', 'Naive Bayes'\n",
    "                     , 'Quadratic Discriminant Analysis', 'Radial Kernel'\n",
    "                     , 'Random Forest Classifier', 'Ridge Classifier'\n",
    "                     , 'Linear Kernel', 'Extreme Gradient Boosting']\n",
    "        \n",
    "        algo_dict = {'ada' : 'Ada Boost Classifier',  'catboost' : 'CatBoost Classifier'\n",
    "                     , 'dt' : 'Decision Tree Classifier', 'et' : 'Extra Trees Classifier'\n",
    "                     , 'gbc' : 'Gradient Boosting Classifier', 'gpc' : 'Gaussian Process Classifier'\n",
    "                     , 'knn' : 'K Neighbors Classifier', 'lda' : 'Linear Discriminant Analysis'\n",
    "                     , 'lightgbm' : 'Light Gradient Boosting Machine', 'lr' : 'Logistic Regression'\n",
    "                     , 'mlp' : 'MLP Classifier', 'nb' : 'Naive Bayes'\n",
    "                     , 'qda' : 'Quadratic Discriminant Analysis', 'rbfsvm' : 'SVM - Radial Kernel'\n",
    "                     , 'rf' : 'Random Forest Classifier', 'ridge' : 'Ridge Classifier'\n",
    "                     , 'svm' : 'SVM - Linear Kernel', 'xgboost' : 'Extreme Gradient Boosting'}\n",
    "    return(algo_list, algo_dict)\n",
    "\n",
    "def get_algorithms(threshold):\n",
    "    algo_list, algo_dict = set_aglorithms(threshold)\n",
    "    if threshold == 'TNO':\n",
    "        typ = 'Regression'\n",
    "        select = [20]\n",
    "    else:\n",
    "        typ = 'Classification'\n",
    "        select = [14]\n",
    "    model_keys = easygui.multchoicebox(msg='Choose the Algorithms for {}'.format(typ)\n",
    "                                   , title='Models for Training the {} models'.format(typ)\n",
    "                                   , choices=algo_list\n",
    "                                   , preselect=select)\n",
    "    algorithms = []\n",
    "    for key, value in algo_dict.items():\n",
    "        for model in model_keys:\n",
    "            if model == value:\n",
    "                algorithms.append(key)\n",
    "    algorithms = list(set(algo_dict.keys()) - set(algorithms))\n",
    "    return(algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-19T06:42:43.874Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Selected Molecules list as input list.\n",
      "Input file is D:\\user_std-data.csv\n",
      "\n",
      "user_std-data.csv\n",
      "[2]\n",
      "[14]\n",
      "[20]\n",
      "|_ 47 user_data molecules were found\n",
      "|_ 1.13 sec to read and standardize the data from user_std-data.csv\n",
      "|_ Features generation was initiated\n",
      "|  |_ PaDEL Descriptors calculation was completed\n",
      "|  |_ Mordred Descriptors calculation was completed\n",
      "|  |_ RDKit Descriptors calculation was completed\n",
      "|  |_ PaDEL Fingerprinter fingerprints calculation was completed\n",
      "|  |_ PaDEL ExtendedFingerprinter fingerprints calculation was completed\n",
      "|  |_ PaDEL EStateFingerprinter fingerprints calculation was completed\n",
      "|  |_ PaDEL GraphOnlyFingerprinter fingerprints calculation was completed\n",
      "|  |_ PaDEL MACCSFingerprinter fingerprints calculation was completed\n",
      "|  |_ PaDEL PubchemFingerprinter fingerprints calculation was completed\n",
      "|  |_ PaDEL SubstructureFingerprinter fingerprints calculation was completed\n",
      "|  |_ PaDEL KlekotaRothFingerprinter fingerprints calculation was completed\n",
      "|  |_ PaDEL AtomPairs2DFingerprinter fingerprints calculation was completed\n",
      "|  |_ RDKit MorganFingerprint calculation was completed\n",
      "|  |_ RDKit RDKitFingerprint calculation was completed\n",
      "|  |_ RDKit HashedAtomPairFingerprint calculation was completed\n",
      "|  |_ RDKit HashedTopologicalTorsionFingerprint calculation was completed\n",
      "|  |_ RDKit ErGFingerprint calculation was completed\n",
      "|  |_ RDKit AvalonFingerprint calculation was completed\n",
      "|  |_ RDKit Fingerprints calculation was completed\n",
      "|  |_ jCompound-Mapper DFS fingerprints calculation was completed\n",
      "|  |_ jCompound-Mapper ASP fingerprints calculation was completed\n",
      "|  |_ jCompound-Mapper AT2D fingerprints calculation was completed\n",
      "|  |_ jCompound-Mapper CATS2D fingerprints calculation was completed\n",
      "|  |_ jCompound-Mapper PHAP2POINT2D fingerprints calculation was completed\n",
      "|  |_ jCompound-Mapper PHAP3POINT2D fingerprints calculation was completed\n",
      "|  |_ jCompound-Mapper ECFP fingerprints calculation was completed\n",
      "|  |_ jCompound-Mapper ECFPVariant fingerprints calculation was completed\n",
      "|  |_ jCompound-Mapper LSTAR fingerprints calculation was completed\n",
      "|_ Features generation was completed\n",
      "|_ 3.79 min for descriptors and fingerprints calculation\n",
      "|_ For threshold T10, Feature transformation and pvalue selection was initiated\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_padel, 1078/1444 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_std_padel, 1078/1444 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_rbst_padel, 1078/1444 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_minmax_padel, 1078/1444 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_mordred, 1230/1826 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_std_mordred, 1230/1826 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_rbst_mordred, 1230/1826 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_minmax_mordred, 1230/1826 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_rdkit, 146/208 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_std_rdkit, 146/208 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_rbst_rdkit, 146/208 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_minmax_rdkit, 146/208 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_Fingerprinter, 724/1024 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_Fingerprinter_nopvalue, 724/1024 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_ExtendedFingerprinter, 715/1024 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_ExtendedFingerprinter_nopvalue, 715/1024 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_EStateFingerprinter, 17/79 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_EStateFingerprinter_nopvalue, 17/79 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_GraphOnlyFingerprinter, 348/1024 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_GraphOnlyFingerprinter_nopvalue, 348/1024 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_MACCSFingerprinter, 84/166 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_MACCSFingerprinter_nopvalue, 84/166 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_PubchemFingerprinter, 266/881 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_PubchemFingerprinter_nopvalue, 266/881 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_SubstructureFingerprinter, 30/307 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_SubstructureFingerprinter_nopvalue, 30/307 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_KlekotaRothFingerprinter, 227/4860 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_KlekotaRothFingerprinter_nopvalue, 227/4860 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_AtomPairs2DFingerprinter, 123/780 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_AtomPairs2DFingerprinter_nopvalue, 123/780 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_MorganFingerprint, 241/2048 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_MorganFingerprint_nopvalue, 241/2048 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_RDKitFingerprint, 1601/2048 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_RDKitFingerprint_nopvalue, 1601/2048 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_HashedAtomPairFingerprint, 980/2048 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_HashedAtomPairFingerprint_nopvalue, 980/2048 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_HashedTopologicalTorsionFingerprint, 248/2048 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_HashedTopologicalTorsionFingerprint_nopvalue, 248/2048 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_ErGFingerprint, 188/315 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_ErGFingerprint_nopvalue, 188/315 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_AvalonFingerprint, 341/512 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_AvalonFingerprint_nopvalue, 341/512 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_DFSFingerprint, 1987/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_DFSFingerprint_nopvalue, 1987/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_ASPFingerprint, 1116/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_ASPFingerprint_nopvalue, 1116/4096 Selected_Features(pvalue)/Total_Features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_AT2DFingerprint, 2664/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_AT2DFingerprint_nopvalue, 2664/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_CATS2DFingerprint, 0/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_CATS2DFingerprint_nopvalue, 0/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_PHAP2POINT2DFingerprint, 8/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_PHAP2POINT2DFingerprint_nopvalue, 8/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_PHAP3POINT2DFingerprint, 160/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_PHAP3POINT2DFingerprint_nopvalue, 160/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_ECFPFingerprint, 890/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_ECFPFingerprint_nopvalue, 890/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_ECFPVariantFingerprint, 606/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_ECFPVariantFingerprint_nopvalue, 606/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_No Descriptor is having a pvalue less than 0.05\n",
      "|  |_ For set:T10_notrans_LSTARFingerprint, 1299/4096 Selected_Features(pvalue)/Total_Features\n",
      "|  |_ For set:T10_notrans_LSTARFingerprint_nopvalue, 1299/4096 Selected_Features(pvalue)/Total_Features\n",
      "|_ For threshold: T10, feature transformation and pvalue selection was completed\n",
      "|_ 2.15 min for feature transformation and pvalue selection\n",
      "|_ For T10, a total of 60 feature sets are transformed and are ready for feature selection\n",
      "|_ For threshold: T10, feature selection was initiated\n",
      "|  |_ For T10_notrans_padel descriptor set Variance selected 536 descriptors\n",
      "|  |_ For T10_notrans_padel descriptor set Log.Reg.-L1 selected 0 descriptors\n",
      "|  |_ For T10_notrans_padel descriptor set Random Forest selected 64 descriptors\n",
      "|  |_ For T10_notrans_padel descriptor set weka-cfs-Bestfirst-fwd selected 56 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_std_padel descriptor set Variance selected 1078 descriptors\n",
      "|  |_ For T10_std_padel descriptor set Log.Reg.-L1 selected 143 descriptors\n",
      "|  |_ For T10_std_padel descriptor set Random Forest selected 62 descriptors\n",
      "|  |_ For T10_std_padel descriptor set weka-cfs-Bestfirst-fwd selected 56 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_rbst_padel descriptor set Variance selected 1001 descriptors\n",
      "|  |_ For T10_rbst_padel descriptor set Log.Reg.-L1 selected 0 descriptors\n",
      "|  |_ For T10_rbst_padel descriptor set Random Forest selected 62 descriptors\n",
      "|  |_ For T10_rbst_padel descriptor set weka-cfs-Bestfirst-fwd selected 56 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_minmax_padel descriptor set Variance selected 4 descriptors\n",
      "|  |_ For T10_minmax_padel descriptor set Log.Reg.-L1 selected 53 descriptors\n",
      "|  |_ For T10_minmax_padel descriptor set Random Forest selected 55 descriptors\n",
      "|  |_ For T10_minmax_padel descriptor set weka-cfs-Bestfirst-fwd selected 56 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_mordred descriptor set Variance selected 600 descriptors\n",
      "|  |_ For T10_notrans_mordred descriptor set Log.Reg.-L1 selected 17 descriptors\n",
      "|  |_ For T10_notrans_mordred descriptor set Random Forest selected 54 descriptors\n",
      "|  |_ For T10_notrans_mordred descriptor set weka-cfs-Bestfirst-fwd selected 56 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_std_mordred descriptor set Variance selected 1230 descriptors\n",
      "|  |_ For T10_std_mordred descriptor set Log.Reg.-L1 selected 171 descriptors\n",
      "|  |_ For T10_std_mordred descriptor set Random Forest selected 62 descriptors\n",
      "|  |_ For T10_std_mordred descriptor set weka-cfs-Bestfirst-fwd selected 63 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_rbst_mordred descriptor set Variance selected 1162 descriptors\n",
      "|  |_ For T10_rbst_mordred descriptor set Log.Reg.-L1 selected 0 descriptors\n",
      "|  |_ For T10_rbst_mordred descriptor set Random Forest selected 55 descriptors\n",
      "|  |_ For T10_rbst_mordred descriptor set weka-cfs-Bestfirst-fwd selected 63 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_minmax_mordred descriptor set Variance selected 10 descriptors\n",
      "|  |_ For T10_minmax_mordred descriptor set Log.Reg.-L1 selected 87 descriptors\n",
      "|  |_ For T10_minmax_mordred descriptor set Random Forest selected 61 descriptors\n",
      "|  |_ For T10_minmax_mordred descriptor set weka-cfs-Bestfirst-fwd selected 63 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_rdkit descriptor set Variance selected 113 descriptors\n",
      "|  |_ For T10_notrans_rdkit descriptor set Log.Reg.-L1 selected 0 descriptors\n",
      "|  |_ For T10_notrans_rdkit descriptor set Random Forest selected 34 descriptors\n",
      "|  |_ For T10_notrans_rdkit descriptor set weka-cfs-Bestfirst-fwd selected 19 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_std_rdkit descriptor set Variance selected 146 descriptors\n",
      "|  |_ For T10_std_rdkit descriptor set Log.Reg.-L1 selected 7 descriptors\n",
      "|  |_ For T10_std_rdkit descriptor set Random Forest selected 39 descriptors\n",
      "|  |_ For T10_std_rdkit descriptor set weka-cfs-Bestfirst-fwd selected 19 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_rbst_rdkit descriptor set Variance selected 130 descriptors\n",
      "|  |_ For T10_rbst_rdkit descriptor set Log.Reg.-L1 selected 109 descriptors\n",
      "|  |_ For T10_rbst_rdkit descriptor set Random Forest selected 32 descriptors\n",
      "|  |_ For T10_rbst_rdkit descriptor set weka-cfs-Bestfirst-fwd selected 19 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_minmax_rdkit descriptor set Variance selected 2 descriptors\n",
      "|  |_ For T10_minmax_rdkit descriptor set Log.Reg.-L1 selected 5 descriptors\n",
      "|  |_ For T10_minmax_rdkit descriptor set Random Forest selected 37 descriptors\n",
      "|  |_ For T10_minmax_rdkit descriptor set weka-cfs-Bestfirst-fwd selected 19 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_Fingerprinter descriptor set Variance selected 165 descriptors\n",
      "|  |_ For T10_notrans_Fingerprinter descriptor set Log.Reg.-L1 selected 54 descriptors\n",
      "|  |_ For T10_notrans_Fingerprinter descriptor set Random Forest selected 52 descriptors\n",
      "|  |_ For T10_notrans_Fingerprinter descriptor set weka-cfs-Bestfirst-fwd selected 124 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_Fingerprinter_nopvalue descriptor set NO METHOD selected 724 descriptors\n",
      "|  |_ For T10_notrans_ExtendedFingerprinter descriptor set Variance selected 159 descriptors\n",
      "|  |_ For T10_notrans_ExtendedFingerprinter descriptor set Log.Reg.-L1 selected 43 descriptors\n",
      "|  |_ For T10_notrans_ExtendedFingerprinter descriptor set Random Forest selected 59 descriptors\n",
      "|  |_ For T10_notrans_ExtendedFingerprinter descriptor set weka-cfs-Bestfirst-fwd selected 112 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_ExtendedFingerprinter_nopvalue descriptor set NO METHOD selected 715 descriptors\n",
      "|  |_ For T10_notrans_EStateFingerprinter descriptor set Variance selected 3 descriptors\n",
      "|  |_ For T10_notrans_EStateFingerprinter descriptor set Log.Reg.-L1 selected 0 descriptors\n",
      "|  |_ For T10_notrans_EStateFingerprinter descriptor set Random Forest selected 4 descriptors\n",
      "|  |_ For T10_notrans_EStateFingerprinter descriptor set weka-cfs-Bestfirst-fwd selected 2 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_EStateFingerprinter_nopvalue descriptor set NO METHOD selected 17 descriptors\n",
      "|  |_ For T10_notrans_GraphOnlyFingerprinter descriptor set Variance selected 15 descriptors\n",
      "|  |_ For T10_notrans_GraphOnlyFingerprinter descriptor set Log.Reg.-L1 selected 16 descriptors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  |_ For T10_notrans_GraphOnlyFingerprinter descriptor set Random Forest selected 54 descriptors\n",
      "|  |_ For T10_notrans_GraphOnlyFingerprinter descriptor set weka-cfs-Bestfirst-fwd selected 25 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_GraphOnlyFingerprinter_nopvalue descriptor set NO METHOD selected 348 descriptors\n",
      "|  |_ For T10_notrans_MACCSFingerprinter descriptor set Variance selected 18 descriptors\n",
      "|  |_ For T10_notrans_MACCSFingerprinter descriptor set Log.Reg.-L1 selected 7 descriptors\n",
      "|  |_ For T10_notrans_MACCSFingerprinter descriptor set Random Forest selected 20 descriptors\n",
      "|  |_ For T10_notrans_MACCSFingerprinter descriptor set weka-cfs-Bestfirst-fwd selected 14 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_MACCSFingerprinter_nopvalue descriptor set NO METHOD selected 84 descriptors\n",
      "|  |_ For T10_notrans_PubchemFingerprinter descriptor set Variance selected 35 descriptors\n",
      "|  |_ For T10_notrans_PubchemFingerprinter descriptor set Log.Reg.-L1 selected 10 descriptors\n",
      "|  |_ For T10_notrans_PubchemFingerprinter descriptor set Random Forest selected 37 descriptors\n",
      "|  |_ For T10_notrans_PubchemFingerprinter descriptor set weka-cfs-Bestfirst-fwd selected 26 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_PubchemFingerprinter_nopvalue descriptor set NO METHOD selected 266 descriptors\n",
      "|  |_ For T10_notrans_SubstructureFingerprinter descriptor set Variance selected 1 descriptors\n",
      "|  |_ For T10_notrans_SubstructureFingerprinter descriptor set Log.Reg.-L1 selected 0 descriptors\n",
      "|  |_ For T10_notrans_SubstructureFingerprinter descriptor set Random Forest selected 7 descriptors\n",
      "|  |_ For T10_notrans_SubstructureFingerprinter descriptor set weka-cfs-Bestfirst-fwd selected 4 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_SubstructureFingerprinter_nopvalue descriptor set NO METHOD selected 30 descriptors\n",
      "|  |_ For T10_notrans_KlekotaRothFingerprinter descriptor set Variance selected 29 descriptors\n",
      "|  |_ For T10_notrans_KlekotaRothFingerprinter descriptor set Log.Reg.-L1 selected 11 descriptors\n",
      "|  |_ For T10_notrans_KlekotaRothFingerprinter descriptor set Random Forest selected 32 descriptors\n",
      "|  |_ For T10_notrans_KlekotaRothFingerprinter descriptor set weka-cfs-Bestfirst-fwd selected 46 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_KlekotaRothFingerprinter_nopvalue descriptor set NO METHOD selected 227 descriptors\n",
      "|  |_ For T10_notrans_AtomPairs2DFingerprinter descriptor set Variance selected 10 descriptors\n",
      "|  |_ For T10_notrans_AtomPairs2DFingerprinter descriptor set Log.Reg.-L1 selected 6 descriptors\n",
      "|  |_ For T10_notrans_AtomPairs2DFingerprinter descriptor set Random Forest selected 23 descriptors\n",
      "|  |_ For T10_notrans_AtomPairs2DFingerprinter descriptor set weka-cfs-Bestfirst-fwd selected 9 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_AtomPairs2DFingerprinter_nopvalue descriptor set NO METHOD selected 123 descriptors\n",
      "|  |_ For T10_notrans_MorganFingerprint descriptor set Variance selected 26 descriptors\n",
      "|  |_ For T10_notrans_MorganFingerprint descriptor set Log.Reg.-L1 selected 8 descriptors\n",
      "|  |_ For T10_notrans_MorganFingerprint descriptor set Random Forest selected 33 descriptors\n",
      "|  |_ For T10_notrans_MorganFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 32 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_MorganFingerprint_nopvalue descriptor set NO METHOD selected 241 descriptors\n",
      "|  |_ For T10_notrans_RDKitFingerprint descriptor set Variance selected 532 descriptors\n",
      "|  |_ For T10_notrans_RDKitFingerprint descriptor set Log.Reg.-L1 selected 117 descriptors\n",
      "|  |_ For T10_notrans_RDKitFingerprint descriptor set Random Forest selected 59 descriptors\n",
      "|  |_ For T10_notrans_RDKitFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 215 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_RDKitFingerprint_nopvalue descriptor set NO METHOD selected 1601 descriptors\n",
      "|  |_ For T10_notrans_HashedAtomPairFingerprint descriptor set Variance selected 184 descriptors\n",
      "|  |_ For T10_notrans_HashedAtomPairFingerprint descriptor set Log.Reg.-L1 selected 53 descriptors\n",
      "|  |_ For T10_notrans_HashedAtomPairFingerprint descriptor set Random Forest selected 56 descriptors\n",
      "|  |_ For T10_notrans_HashedAtomPairFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 43 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_HashedAtomPairFingerprint_nopvalue descriptor set NO METHOD selected 980 descriptors\n",
      "|  |_ For T10_notrans_HashedTopologicalTorsionFingerprint descriptor set Variance selected 34 descriptors\n",
      "|  |_ For T10_notrans_HashedTopologicalTorsionFingerprint descriptor set Log.Reg.-L1 selected 19 descriptors\n",
      "|  |_ For T10_notrans_HashedTopologicalTorsionFingerprint descriptor set Random Forest selected 39 descriptors\n",
      "|  |_ For T10_notrans_HashedTopologicalTorsionFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 51 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_HashedTopologicalTorsionFingerprint_nopvalue descriptor set NO METHOD selected 248 descriptors\n",
      "|  |_ For T10_notrans_ErGFingerprint descriptor set Variance selected 68 descriptors\n",
      "|  |_ For T10_notrans_ErGFingerprint descriptor set Log.Reg.-L1 selected 10 descriptors\n",
      "|  |_ For T10_notrans_ErGFingerprint descriptor set Random Forest selected 36 descriptors\n",
      "|  |_ For T10_notrans_ErGFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 23 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_ErGFingerprint_nopvalue descriptor set NO METHOD selected 188 descriptors\n",
      "|  |_ For T10_notrans_AvalonFingerprint descriptor set Variance selected 59 descriptors\n",
      "|  |_ For T10_notrans_AvalonFingerprint descriptor set Log.Reg.-L1 selected 15 descriptors\n",
      "|  |_ For T10_notrans_AvalonFingerprint descriptor set Random Forest selected 38 descriptors\n",
      "|  |_ For T10_notrans_AvalonFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 49 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_AvalonFingerprint_nopvalue descriptor set NO METHOD selected 341 descriptors\n",
      "|  |_ For T10_notrans_DFSFingerprint descriptor set Variance selected 261 descriptors\n",
      "|  |_ For T10_notrans_DFSFingerprint descriptor set Log.Reg.-L1 selected 51 descriptors\n",
      "|  |_ For T10_notrans_DFSFingerprint descriptor set Random Forest selected 63 descriptors\n",
      "|  |_ For T10_notrans_DFSFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 377 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_DFSFingerprint_nopvalue descriptor set NO METHOD selected 1987 descriptors\n",
      "|  |_ For T10_notrans_ASPFingerprint descriptor set Variance selected 166 descriptors\n",
      "|  |_ For T10_notrans_ASPFingerprint descriptor set Log.Reg.-L1 selected 31 descriptors\n",
      "|  |_ For T10_notrans_ASPFingerprint descriptor set Random Forest selected 50 descriptors\n",
      "|  |_ For T10_notrans_ASPFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 131 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_ASPFingerprint_nopvalue descriptor set NO METHOD selected 1116 descriptors\n",
      "|  |_ For T10_notrans_AT2DFingerprint descriptor set Variance selected 581 descriptors\n",
      "|  |_ For T10_notrans_AT2DFingerprint descriptor set Log.Reg.-L1 selected 133 descriptors\n",
      "|  |_ For T10_notrans_AT2DFingerprint descriptor set Random Forest selected 58 descriptors\n",
      "|  |_ For T10_notrans_AT2DFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 141 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_AT2DFingerprint_nopvalue descriptor set NO METHOD selected 2664 descriptors\n",
      "|  |_ For T10_notrans_CATS2DFingerprint descriptor set NO METHOD selected 0 descriptors\n",
      "|  |_ For T10_notrans_CATS2DFingerprint_nopvalue descriptor set NO METHOD selected 0 descriptors\n",
      "|  |_ For T10_notrans_PHAP2POINT2DFingerprint descriptor set Variance selected 2 descriptors\n",
      "|  |_ For T10_notrans_PHAP2POINT2DFingerprint descriptor set Log.Reg.-L1 selected 0 descriptors\n",
      "|  |_ For T10_notrans_PHAP2POINT2DFingerprint descriptor set Random Forest selected 1 descriptors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  |_ For T10_notrans_PHAP2POINT2DFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 1 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_PHAP2POINT2DFingerprint_nopvalue descriptor set NO METHOD selected 8 descriptors\n",
      "|  |_ For T10_notrans_PHAP3POINT2DFingerprint descriptor set Variance selected 5 descriptors\n",
      "|  |_ For T10_notrans_PHAP3POINT2DFingerprint descriptor set Log.Reg.-L1 selected 33 descriptors\n",
      "|  |_ For T10_notrans_PHAP3POINT2DFingerprint descriptor set Random Forest selected 31 descriptors\n",
      "|  |_ For T10_notrans_PHAP3POINT2DFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 18 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_PHAP3POINT2DFingerprint_nopvalue descriptor set NO METHOD selected 160 descriptors\n",
      "|  |_ For T10_notrans_ECFPFingerprint descriptor set Variance selected 53 descriptors\n",
      "|  |_ For T10_notrans_ECFPFingerprint descriptor set Log.Reg.-L1 selected 11 descriptors\n",
      "|  |_ For T10_notrans_ECFPFingerprint descriptor set Random Forest selected 44 descriptors\n",
      "|  |_ For T10_notrans_ECFPFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 62 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_ECFPFingerprint_nopvalue descriptor set NO METHOD selected 890 descriptors\n",
      "|  |_ For T10_notrans_ECFPVariantFingerprint descriptor set Variance selected 48 descriptors\n",
      "|  |_ For T10_notrans_ECFPVariantFingerprint descriptor set Log.Reg.-L1 selected 11 descriptors\n",
      "|  |_ For T10_notrans_ECFPVariantFingerprint descriptor set Random Forest selected 39 descriptors\n",
      "|  |_ For T10_notrans_ECFPVariantFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 51 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_ECFPVariantFingerprint_nopvalue descriptor set NO METHOD selected 606 descriptors\n",
      "|  |_ For T10_notrans_LSTARFingerprint descriptor set Variance selected 98 descriptors\n",
      "|  |_ For T10_notrans_LSTARFingerprint descriptor set Log.Reg.-L1 selected 16 descriptors\n",
      "|  |_ For T10_notrans_LSTARFingerprint descriptor set Random Forest selected 52 descriptors\n",
      "|  |_ For T10_notrans_LSTARFingerprint descriptor set weka-cfs-Bestfirst-fwd selected 86 descriptors\n",
      "|  |  |_ fwd and bid are same. Deleting bid\n",
      "|  |_ For T10_notrans_LSTARFingerprint_nopvalue descriptor set NO METHOD selected 1299 descriptors\n",
      "|_ For threshold: T10, feature selection was completed\n",
      "|_ 6.13 min for feature selection\n",
      "|_ For T10, a total of 158 feature sets are ready for model generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/12/19 12:25:58 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for T10_notrans_padel_Var: model results\n",
      "                       Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "   TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0     4.305            None  T10_notrans_padel_Var             536  \n",
      "Results for T10_notrans_padel_Rf: model results\n",
      "                       Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "   TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0     4.305            None  T10_notrans_padel_Var             536  \n",
      "1     0.175            None   T10_notrans_padel_Rf              64  \n",
      "Results for T10_notrans_padel_fwd: model results\n",
      "                       Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "   TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0     4.305            None  T10_notrans_padel_Var             536  \n",
      "1     0.175            None   T10_notrans_padel_Rf              64  \n",
      "2     0.177            None  T10_notrans_padel_fwd              56  \n",
      "Results for T10_std_padel_Var: model results\n",
      "                       Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "   TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0     4.305            None  T10_notrans_padel_Var             536  \n",
      "1     0.175            None   T10_notrans_padel_Rf              64  \n",
      "2     0.177            None  T10_notrans_padel_fwd              56  \n",
      "3     0.208            None      T10_std_padel_Var            1078  \n",
      "Results for T10_std_padel_Lor: model results\n",
      "                       Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "   TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0     4.305            None  T10_notrans_padel_Var             536  \n",
      "1     0.175            None   T10_notrans_padel_Rf              64  \n",
      "2     0.177            None  T10_notrans_padel_fwd              56  \n",
      "3     0.208            None      T10_std_padel_Var            1078  \n",
      "4     0.186            None      T10_std_padel_Lor             143  \n",
      "Results for T10_std_padel_Rf: model results\n",
      "                       Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "   TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0     4.305            None  T10_notrans_padel_Var             536  \n",
      "1     0.175            None   T10_notrans_padel_Rf              64  \n",
      "2     0.177            None  T10_notrans_padel_fwd              56  \n",
      "3     0.208            None      T10_std_padel_Var            1078  \n",
      "4     0.186            None      T10_std_padel_Lor             143  \n",
      "5     0.207            None       T10_std_padel_Rf              62  \n",
      "Results for T10_std_padel_fwd: model results\n",
      "                       Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "   TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0     4.305            None  T10_notrans_padel_Var             536  \n",
      "1     0.175            None   T10_notrans_padel_Rf              64  \n",
      "2     0.177            None  T10_notrans_padel_fwd              56  \n",
      "3     0.208            None      T10_std_padel_Var            1078  \n",
      "4     0.186            None      T10_std_padel_Lor             143  \n",
      "5     0.207            None       T10_std_padel_Rf              62  \n",
      "6     0.184            None      T10_std_padel_fwd              56  \n",
      "Results for T10_rbst_padel_Var: model results\n",
      "                       Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "   TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0     4.305            None  T10_notrans_padel_Var             536  \n",
      "1     0.175            None   T10_notrans_padel_Rf              64  \n",
      "2     0.177            None  T10_notrans_padel_fwd              56  \n",
      "3     0.208            None      T10_std_padel_Var            1078  \n",
      "4     0.186            None      T10_std_padel_Lor             143  \n",
      "5     0.207            None       T10_std_padel_Rf              62  \n",
      "6     0.184            None      T10_std_padel_fwd              56  \n",
      "7     0.194            None     T10_rbst_padel_Var            1001  \n",
      "Results for T10_rbst_padel_Rf: model results\n",
      "                       Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "   TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0     4.305            None  T10_notrans_padel_Var             536  \n",
      "1     0.175            None   T10_notrans_padel_Rf              64  \n",
      "2     0.177            None  T10_notrans_padel_fwd              56  \n",
      "3     0.208            None      T10_std_padel_Var            1078  \n",
      "4     0.186            None      T10_std_padel_Lor             143  \n",
      "5     0.207            None       T10_std_padel_Rf              62  \n",
      "6     0.184            None      T10_std_padel_fwd              56  \n",
      "7     0.194            None     T10_rbst_padel_Var            1001  \n",
      "8     0.190            None      T10_rbst_padel_Rf              62  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for T10_rbst_padel_fwd: model results\n",
      "                       Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "   TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0     4.305            None  T10_notrans_padel_Var             536  \n",
      "1     0.175            None   T10_notrans_padel_Rf              64  \n",
      "2     0.177            None  T10_notrans_padel_fwd              56  \n",
      "3     0.208            None      T10_std_padel_Var            1078  \n",
      "4     0.186            None      T10_std_padel_Lor             143  \n",
      "5     0.207            None       T10_std_padel_Rf              62  \n",
      "6     0.184            None      T10_std_padel_fwd              56  \n",
      "7     0.194            None     T10_rbst_padel_Var            1001  \n",
      "8     0.190            None      T10_rbst_padel_Rf              62  \n",
      "9     0.174            None     T10_rbst_padel_fwd              56  \n",
      "Results for T10_minmax_padel_Var: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0      4.305            None  T10_notrans_padel_Var             536  \n",
      "1      0.175            None   T10_notrans_padel_Rf              64  \n",
      "2      0.177            None  T10_notrans_padel_fwd              56  \n",
      "3      0.208            None      T10_std_padel_Var            1078  \n",
      "4      0.186            None      T10_std_padel_Lor             143  \n",
      "5      0.207            None       T10_std_padel_Rf              62  \n",
      "6      0.184            None      T10_std_padel_fwd              56  \n",
      "7      0.194            None     T10_rbst_padel_Var            1001  \n",
      "8      0.190            None      T10_rbst_padel_Rf              62  \n",
      "9      0.174            None     T10_rbst_padel_fwd              56  \n",
      "10     0.202            None   T10_minmax_padel_Var               4  \n",
      "Results for T10_minmax_padel_Lor: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0      4.305            None  T10_notrans_padel_Var             536  \n",
      "1      0.175            None   T10_notrans_padel_Rf              64  \n",
      "2      0.177            None  T10_notrans_padel_fwd              56  \n",
      "3      0.208            None      T10_std_padel_Var            1078  \n",
      "4      0.186            None      T10_std_padel_Lor             143  \n",
      "5      0.207            None       T10_std_padel_Rf              62  \n",
      "6      0.184            None      T10_std_padel_fwd              56  \n",
      "7      0.194            None     T10_rbst_padel_Var            1001  \n",
      "8      0.190            None      T10_rbst_padel_Rf              62  \n",
      "9      0.174            None     T10_rbst_padel_fwd              56  \n",
      "10     0.202            None   T10_minmax_padel_Var               4  \n",
      "11     0.197            None   T10_minmax_padel_Lor              53  \n",
      "Results for T10_minmax_padel_Rf: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0      4.305            None  T10_notrans_padel_Var             536  \n",
      "1      0.175            None   T10_notrans_padel_Rf              64  \n",
      "2      0.177            None  T10_notrans_padel_fwd              56  \n",
      "3      0.208            None      T10_std_padel_Var            1078  \n",
      "4      0.186            None      T10_std_padel_Lor             143  \n",
      "5      0.207            None       T10_std_padel_Rf              62  \n",
      "6      0.184            None      T10_std_padel_fwd              56  \n",
      "7      0.194            None     T10_rbst_padel_Var            1001  \n",
      "8      0.190            None      T10_rbst_padel_Rf              62  \n",
      "9      0.174            None     T10_rbst_padel_fwd              56  \n",
      "10     0.202            None   T10_minmax_padel_Var               4  \n",
      "11     0.197            None   T10_minmax_padel_Lor              53  \n",
      "12     0.193            None    T10_minmax_padel_Rf              55  \n",
      "Results for T10_minmax_padel_fwd: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method thresh_std_feature_set  features_count  \n",
      "0      4.305            None  T10_notrans_padel_Var             536  \n",
      "1      0.175            None   T10_notrans_padel_Rf              64  \n",
      "2      0.177            None  T10_notrans_padel_fwd              56  \n",
      "3      0.208            None      T10_std_padel_Var            1078  \n",
      "4      0.186            None      T10_std_padel_Lor             143  \n",
      "5      0.207            None       T10_std_padel_Rf              62  \n",
      "6      0.184            None      T10_std_padel_fwd              56  \n",
      "7      0.194            None     T10_rbst_padel_Var            1001  \n",
      "8      0.190            None      T10_rbst_padel_Rf              62  \n",
      "9      0.174            None     T10_rbst_padel_fwd              56  \n",
      "10     0.202            None   T10_minmax_padel_Var               4  \n",
      "11     0.197            None   T10_minmax_padel_Lor              53  \n",
      "12     0.193            None    T10_minmax_padel_Rf              55  \n",
      "13     0.186            None   T10_minmax_padel_fwd              56  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for T10_notrans_mordred_Var: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "14  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0      4.305            None    T10_notrans_padel_Var             536  \n",
      "1      0.175            None     T10_notrans_padel_Rf              64  \n",
      "2      0.177            None    T10_notrans_padel_fwd              56  \n",
      "3      0.208            None        T10_std_padel_Var            1078  \n",
      "4      0.186            None        T10_std_padel_Lor             143  \n",
      "5      0.207            None         T10_std_padel_Rf              62  \n",
      "6      0.184            None        T10_std_padel_fwd              56  \n",
      "7      0.194            None       T10_rbst_padel_Var            1001  \n",
      "8      0.190            None        T10_rbst_padel_Rf              62  \n",
      "9      0.174            None       T10_rbst_padel_fwd              56  \n",
      "10     0.202            None     T10_minmax_padel_Var               4  \n",
      "11     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14     0.200            None  T10_notrans_mordred_Var             600  \n",
      "Results for T10_notrans_mordred_Lor: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "14  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "15  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0      4.305            None    T10_notrans_padel_Var             536  \n",
      "1      0.175            None     T10_notrans_padel_Rf              64  \n",
      "2      0.177            None    T10_notrans_padel_fwd              56  \n",
      "3      0.208            None        T10_std_padel_Var            1078  \n",
      "4      0.186            None        T10_std_padel_Lor             143  \n",
      "5      0.207            None         T10_std_padel_Rf              62  \n",
      "6      0.184            None        T10_std_padel_fwd              56  \n",
      "7      0.194            None       T10_rbst_padel_Var            1001  \n",
      "8      0.190            None        T10_rbst_padel_Rf              62  \n",
      "9      0.174            None       T10_rbst_padel_fwd              56  \n",
      "10     0.202            None     T10_minmax_padel_Var               4  \n",
      "11     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "Results for T10_notrans_mordred_Rf: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "14  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "15  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "16  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0      4.305            None    T10_notrans_padel_Var             536  \n",
      "1      0.175            None     T10_notrans_padel_Rf              64  \n",
      "2      0.177            None    T10_notrans_padel_fwd              56  \n",
      "3      0.208            None        T10_std_padel_Var            1078  \n",
      "4      0.186            None        T10_std_padel_Lor             143  \n",
      "5      0.207            None         T10_std_padel_Rf              62  \n",
      "6      0.184            None        T10_std_padel_fwd              56  \n",
      "7      0.194            None       T10_rbst_padel_Var            1001  \n",
      "8      0.190            None        T10_rbst_padel_Rf              62  \n",
      "9      0.174            None       T10_rbst_padel_fwd              56  \n",
      "10     0.202            None     T10_minmax_padel_Var               4  \n",
      "11     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "Results for T10_notrans_mordred_fwd: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "14  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "15  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "16  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "17  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0      4.305            None    T10_notrans_padel_Var             536  \n",
      "1      0.175            None     T10_notrans_padel_Rf              64  \n",
      "2      0.177            None    T10_notrans_padel_fwd              56  \n",
      "3      0.208            None        T10_std_padel_Var            1078  \n",
      "4      0.186            None        T10_std_padel_Lor             143  \n",
      "5      0.207            None         T10_std_padel_Rf              62  \n",
      "6      0.184            None        T10_std_padel_fwd              56  \n",
      "7      0.194            None       T10_rbst_padel_Var            1001  \n",
      "8      0.190            None        T10_rbst_padel_Rf              62  \n",
      "9      0.174            None       T10_rbst_padel_fwd              56  \n",
      "10     0.202            None     T10_minmax_padel_Var               4  \n",
      "11     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17     0.194            None  T10_notrans_mordred_fwd              56  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for T10_std_mordred_Var: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "14  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "15  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "16  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "17  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "18  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0      4.305            None    T10_notrans_padel_Var             536  \n",
      "1      0.175            None     T10_notrans_padel_Rf              64  \n",
      "2      0.177            None    T10_notrans_padel_fwd              56  \n",
      "3      0.208            None        T10_std_padel_Var            1078  \n",
      "4      0.186            None        T10_std_padel_Lor             143  \n",
      "5      0.207            None         T10_std_padel_Rf              62  \n",
      "6      0.184            None        T10_std_padel_fwd              56  \n",
      "7      0.194            None       T10_rbst_padel_Var            1001  \n",
      "8      0.190            None        T10_rbst_padel_Rf              62  \n",
      "9      0.174            None       T10_rbst_padel_fwd              56  \n",
      "10     0.202            None     T10_minmax_padel_Var               4  \n",
      "11     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17     0.194            None  T10_notrans_mordred_fwd              56  \n",
      "18     0.215            None      T10_std_mordred_Var            1230  \n",
      "Results for T10_std_mordred_Lor: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "14  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "15  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "16  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "17  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "18  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "19  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0      4.305            None    T10_notrans_padel_Var             536  \n",
      "1      0.175            None     T10_notrans_padel_Rf              64  \n",
      "2      0.177            None    T10_notrans_padel_fwd              56  \n",
      "3      0.208            None        T10_std_padel_Var            1078  \n",
      "4      0.186            None        T10_std_padel_Lor             143  \n",
      "5      0.207            None         T10_std_padel_Rf              62  \n",
      "6      0.184            None        T10_std_padel_fwd              56  \n",
      "7      0.194            None       T10_rbst_padel_Var            1001  \n",
      "8      0.190            None        T10_rbst_padel_Rf              62  \n",
      "9      0.174            None       T10_rbst_padel_fwd              56  \n",
      "10     0.202            None     T10_minmax_padel_Var               4  \n",
      "11     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17     0.194            None  T10_notrans_mordred_fwd              56  \n",
      "18     0.215            None      T10_std_mordred_Var            1230  \n",
      "19     0.202            None      T10_std_mordred_Lor             171  \n",
      "Results for T10_std_mordred_Rf: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "14  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "15  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "16  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "17  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "18  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "19  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "20  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0      4.305            None    T10_notrans_padel_Var             536  \n",
      "1      0.175            None     T10_notrans_padel_Rf              64  \n",
      "2      0.177            None    T10_notrans_padel_fwd              56  \n",
      "3      0.208            None        T10_std_padel_Var            1078  \n",
      "4      0.186            None        T10_std_padel_Lor             143  \n",
      "5      0.207            None         T10_std_padel_Rf              62  \n",
      "6      0.184            None        T10_std_padel_fwd              56  \n",
      "7      0.194            None       T10_rbst_padel_Var            1001  \n",
      "8      0.190            None        T10_rbst_padel_Rf              62  \n",
      "9      0.174            None       T10_rbst_padel_fwd              56  \n",
      "10     0.202            None     T10_minmax_padel_Var               4  \n",
      "11     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17     0.194            None  T10_notrans_mordred_fwd              56  \n",
      "18     0.215            None      T10_std_mordred_Var            1230  \n",
      "19     0.202            None      T10_std_mordred_Lor             171  \n",
      "20     0.193            None       T10_std_mordred_Rf              62  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for T10_std_mordred_fwd: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "14  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "15  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "16  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "17  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "18  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "19  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "20  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "21  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0      4.305            None    T10_notrans_padel_Var             536  \n",
      "1      0.175            None     T10_notrans_padel_Rf              64  \n",
      "2      0.177            None    T10_notrans_padel_fwd              56  \n",
      "3      0.208            None        T10_std_padel_Var            1078  \n",
      "4      0.186            None        T10_std_padel_Lor             143  \n",
      "5      0.207            None         T10_std_padel_Rf              62  \n",
      "6      0.184            None        T10_std_padel_fwd              56  \n",
      "7      0.194            None       T10_rbst_padel_Var            1001  \n",
      "8      0.190            None        T10_rbst_padel_Rf              62  \n",
      "9      0.174            None       T10_rbst_padel_fwd              56  \n",
      "10     0.202            None     T10_minmax_padel_Var               4  \n",
      "11     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17     0.194            None  T10_notrans_mordred_fwd              56  \n",
      "18     0.215            None      T10_std_mordred_Var            1230  \n",
      "19     0.202            None      T10_std_mordred_Lor             171  \n",
      "20     0.193            None       T10_std_mordred_Rf              62  \n",
      "21     0.174            None      T10_std_mordred_fwd              63  \n",
      "Results for T10_rbst_mordred_Var: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "14  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "15  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "16  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "17  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "18  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "19  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "20  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "21  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "22  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0      4.305            None    T10_notrans_padel_Var             536  \n",
      "1      0.175            None     T10_notrans_padel_Rf              64  \n",
      "2      0.177            None    T10_notrans_padel_fwd              56  \n",
      "3      0.208            None        T10_std_padel_Var            1078  \n",
      "4      0.186            None        T10_std_padel_Lor             143  \n",
      "5      0.207            None         T10_std_padel_Rf              62  \n",
      "6      0.184            None        T10_std_padel_fwd              56  \n",
      "7      0.194            None       T10_rbst_padel_Var            1001  \n",
      "8      0.190            None        T10_rbst_padel_Rf              62  \n",
      "9      0.174            None       T10_rbst_padel_fwd              56  \n",
      "10     0.202            None     T10_minmax_padel_Var               4  \n",
      "11     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17     0.194            None  T10_notrans_mordred_fwd              56  \n",
      "18     0.215            None      T10_std_mordred_Var            1230  \n",
      "19     0.202            None      T10_std_mordred_Lor             171  \n",
      "20     0.193            None       T10_std_mordred_Rf              62  \n",
      "21     0.174            None      T10_std_mordred_fwd              63  \n",
      "22     0.212            None     T10_rbst_mordred_Var            1162  \n",
      "Results for T10_rbst_mordred_Rf: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "14  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "15  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "16  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "17  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "18  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "19  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "20  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "21  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "22  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "23  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0      4.305            None    T10_notrans_padel_Var             536  \n",
      "1      0.175            None     T10_notrans_padel_Rf              64  \n",
      "2      0.177            None    T10_notrans_padel_fwd              56  \n",
      "3      0.208            None        T10_std_padel_Var            1078  \n",
      "4      0.186            None        T10_std_padel_Lor             143  \n",
      "5      0.207            None         T10_std_padel_Rf              62  \n",
      "6      0.184            None        T10_std_padel_fwd              56  \n",
      "7      0.194            None       T10_rbst_padel_Var            1001  \n",
      "8      0.190            None        T10_rbst_padel_Rf              62  \n",
      "9      0.174            None       T10_rbst_padel_fwd              56  \n",
      "10     0.202            None     T10_minmax_padel_Var               4  \n",
      "11     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17     0.194            None  T10_notrans_mordred_fwd              56  \n",
      "18     0.215            None      T10_std_mordred_Var            1230  \n",
      "19     0.202            None      T10_std_mordred_Lor             171  \n",
      "20     0.193            None       T10_std_mordred_Rf              62  \n",
      "21     0.174            None      T10_std_mordred_fwd              63  \n",
      "22     0.212            None     T10_rbst_mordred_Var            1162  \n",
      "23     0.220            None      T10_rbst_mordred_Rf              55  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for T10_rbst_mordred_fwd: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.    F1  Kappa  MCC  \\\n",
      "0   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "1   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "2   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "3   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "4   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "5   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "6   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "7   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "8   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "9   Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "10  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "11  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "12  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "13  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "14  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "15  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "16  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "17  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "18  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "19  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "20  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "21  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "22  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "23  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "24  Random Forest Classifier    0.9667  0.0     1.0  0.9667  0.98    NaN  0.0   \n",
      "\n",
      "    TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0      4.305            None    T10_notrans_padel_Var             536  \n",
      "1      0.175            None     T10_notrans_padel_Rf              64  \n",
      "2      0.177            None    T10_notrans_padel_fwd              56  \n",
      "3      0.208            None        T10_std_padel_Var            1078  \n",
      "4      0.186            None        T10_std_padel_Lor             143  \n",
      "5      0.207            None         T10_std_padel_Rf              62  \n",
      "6      0.184            None        T10_std_padel_fwd              56  \n",
      "7      0.194            None       T10_rbst_padel_Var            1001  \n",
      "8      0.190            None        T10_rbst_padel_Rf              62  \n",
      "9      0.174            None       T10_rbst_padel_fwd              56  \n",
      "10     0.202            None     T10_minmax_padel_Var               4  \n",
      "11     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17     0.194            None  T10_notrans_mordred_fwd              56  \n",
      "18     0.215            None      T10_std_mordred_Var            1230  \n",
      "19     0.202            None      T10_std_mordred_Lor             171  \n",
      "20     0.193            None       T10_std_mordred_Rf              62  \n",
      "21     0.174            None      T10_std_mordred_fwd              63  \n",
      "22     0.212            None     T10_rbst_mordred_Var            1162  \n",
      "23     0.220            None      T10_rbst_mordred_Rf              55  \n",
      "24     0.175            None     T10_rbst_mordred_fwd              63  \n",
      "Results for T10_minmax_mordred_Var: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.      F1  Kappa  \\\n",
      "0   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "1   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "2   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "3   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "4   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "5   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "6   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "7   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "8   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "9   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "10  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "11  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "12  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "13  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "14  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "15  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "16  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "17  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "18  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "19  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "20  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "21  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "22  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "23  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "24  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "25  Random Forest Classifier    0.9167  0.0    0.95  0.9667  0.9467    NaN   \n",
      "\n",
      "    MCC  TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0   0.0     4.305            None    T10_notrans_padel_Var             536  \n",
      "1   0.0     0.175            None     T10_notrans_padel_Rf              64  \n",
      "2   0.0     0.177            None    T10_notrans_padel_fwd              56  \n",
      "3   0.0     0.208            None        T10_std_padel_Var            1078  \n",
      "4   0.0     0.186            None        T10_std_padel_Lor             143  \n",
      "5   0.0     0.207            None         T10_std_padel_Rf              62  \n",
      "6   0.0     0.184            None        T10_std_padel_fwd              56  \n",
      "7   0.0     0.194            None       T10_rbst_padel_Var            1001  \n",
      "8   0.0     0.190            None        T10_rbst_padel_Rf              62  \n",
      "9   0.0     0.174            None       T10_rbst_padel_fwd              56  \n",
      "10  0.0     0.202            None     T10_minmax_padel_Var               4  \n",
      "11  0.0     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12  0.0     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13  0.0     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14  0.0     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15  0.0     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16  0.0     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17  0.0     0.194            None  T10_notrans_mordred_fwd              56  \n",
      "18  0.0     0.215            None      T10_std_mordred_Var            1230  \n",
      "19  0.0     0.202            None      T10_std_mordred_Lor             171  \n",
      "20  0.0     0.193            None       T10_std_mordred_Rf              62  \n",
      "21  0.0     0.174            None      T10_std_mordred_fwd              63  \n",
      "22  0.0     0.212            None     T10_rbst_mordred_Var            1162  \n",
      "23  0.0     0.220            None      T10_rbst_mordred_Rf              55  \n",
      "24  0.0     0.175            None     T10_rbst_mordred_fwd              63  \n",
      "25  0.0     0.195            None   T10_minmax_mordred_Var              10  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for T10_minmax_mordred_Lor: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.      F1  Kappa  \\\n",
      "0   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "1   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "2   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "3   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "4   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "5   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "6   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "7   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "8   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "9   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "10  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "11  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "12  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "13  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "14  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "15  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "16  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "17  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "18  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "19  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "20  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "21  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "22  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "23  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "24  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "25  Random Forest Classifier    0.9167  0.0    0.95  0.9667  0.9467    NaN   \n",
      "26  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "\n",
      "    MCC  TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0   0.0     4.305            None    T10_notrans_padel_Var             536  \n",
      "1   0.0     0.175            None     T10_notrans_padel_Rf              64  \n",
      "2   0.0     0.177            None    T10_notrans_padel_fwd              56  \n",
      "3   0.0     0.208            None        T10_std_padel_Var            1078  \n",
      "4   0.0     0.186            None        T10_std_padel_Lor             143  \n",
      "5   0.0     0.207            None         T10_std_padel_Rf              62  \n",
      "6   0.0     0.184            None        T10_std_padel_fwd              56  \n",
      "7   0.0     0.194            None       T10_rbst_padel_Var            1001  \n",
      "8   0.0     0.190            None        T10_rbst_padel_Rf              62  \n",
      "9   0.0     0.174            None       T10_rbst_padel_fwd              56  \n",
      "10  0.0     0.202            None     T10_minmax_padel_Var               4  \n",
      "11  0.0     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12  0.0     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13  0.0     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14  0.0     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15  0.0     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16  0.0     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17  0.0     0.194            None  T10_notrans_mordred_fwd              56  \n",
      "18  0.0     0.215            None      T10_std_mordred_Var            1230  \n",
      "19  0.0     0.202            None      T10_std_mordred_Lor             171  \n",
      "20  0.0     0.193            None       T10_std_mordred_Rf              62  \n",
      "21  0.0     0.174            None      T10_std_mordred_fwd              63  \n",
      "22  0.0     0.212            None     T10_rbst_mordred_Var            1162  \n",
      "23  0.0     0.220            None      T10_rbst_mordred_Rf              55  \n",
      "24  0.0     0.175            None     T10_rbst_mordred_fwd              63  \n",
      "25  0.0     0.195            None   T10_minmax_mordred_Var              10  \n",
      "26  0.0     0.187            None   T10_minmax_mordred_Lor              87  \n",
      "Results for T10_minmax_mordred_Rf: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.      F1  Kappa  \\\n",
      "0   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "1   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "2   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "3   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "4   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "5   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "6   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "7   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "8   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "9   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "10  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "11  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "12  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "13  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "14  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "15  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "16  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "17  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "18  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "19  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "20  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "21  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "22  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "23  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "24  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "25  Random Forest Classifier    0.9167  0.0    0.95  0.9667  0.9467    NaN   \n",
      "26  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "27  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "\n",
      "    MCC  TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0   0.0     4.305            None    T10_notrans_padel_Var             536  \n",
      "1   0.0     0.175            None     T10_notrans_padel_Rf              64  \n",
      "2   0.0     0.177            None    T10_notrans_padel_fwd              56  \n",
      "3   0.0     0.208            None        T10_std_padel_Var            1078  \n",
      "4   0.0     0.186            None        T10_std_padel_Lor             143  \n",
      "5   0.0     0.207            None         T10_std_padel_Rf              62  \n",
      "6   0.0     0.184            None        T10_std_padel_fwd              56  \n",
      "7   0.0     0.194            None       T10_rbst_padel_Var            1001  \n",
      "8   0.0     0.190            None        T10_rbst_padel_Rf              62  \n",
      "9   0.0     0.174            None       T10_rbst_padel_fwd              56  \n",
      "10  0.0     0.202            None     T10_minmax_padel_Var               4  \n",
      "11  0.0     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12  0.0     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13  0.0     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14  0.0     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15  0.0     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16  0.0     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17  0.0     0.194            None  T10_notrans_mordred_fwd              56  \n",
      "18  0.0     0.215            None      T10_std_mordred_Var            1230  \n",
      "19  0.0     0.202            None      T10_std_mordred_Lor             171  \n",
      "20  0.0     0.193            None       T10_std_mordred_Rf              62  \n",
      "21  0.0     0.174            None      T10_std_mordred_fwd              63  \n",
      "22  0.0     0.212            None     T10_rbst_mordred_Var            1162  \n",
      "23  0.0     0.220            None      T10_rbst_mordred_Rf              55  \n",
      "24  0.0     0.175            None     T10_rbst_mordred_fwd              63  \n",
      "25  0.0     0.195            None   T10_minmax_mordred_Var              10  \n",
      "26  0.0     0.187            None   T10_minmax_mordred_Lor              87  \n",
      "27  0.0     0.178            None    T10_minmax_mordred_Rf              61  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for T10_minmax_mordred_fwd: model results\n",
      "                        Model  Accuracy  AUC  Recall   Prec.      F1  Kappa  \\\n",
      "0   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "1   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "2   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "3   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "4   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "5   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "6   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "7   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "8   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "9   Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "10  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "11  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "12  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "13  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "14  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "15  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "16  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "17  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "18  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "19  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "20  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "21  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "22  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "23  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "24  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "25  Random Forest Classifier    0.9167  0.0    0.95  0.9667  0.9467    NaN   \n",
      "26  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "27  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "28  Random Forest Classifier    0.9667  0.0    1.00  0.9667  0.9800    NaN   \n",
      "\n",
      "    MCC  TT (Sec) sampling_method   thresh_std_feature_set  features_count  \n",
      "0   0.0     4.305            None    T10_notrans_padel_Var             536  \n",
      "1   0.0     0.175            None     T10_notrans_padel_Rf              64  \n",
      "2   0.0     0.177            None    T10_notrans_padel_fwd              56  \n",
      "3   0.0     0.208            None        T10_std_padel_Var            1078  \n",
      "4   0.0     0.186            None        T10_std_padel_Lor             143  \n",
      "5   0.0     0.207            None         T10_std_padel_Rf              62  \n",
      "6   0.0     0.184            None        T10_std_padel_fwd              56  \n",
      "7   0.0     0.194            None       T10_rbst_padel_Var            1001  \n",
      "8   0.0     0.190            None        T10_rbst_padel_Rf              62  \n",
      "9   0.0     0.174            None       T10_rbst_padel_fwd              56  \n",
      "10  0.0     0.202            None     T10_minmax_padel_Var               4  \n",
      "11  0.0     0.197            None     T10_minmax_padel_Lor              53  \n",
      "12  0.0     0.193            None      T10_minmax_padel_Rf              55  \n",
      "13  0.0     0.186            None     T10_minmax_padel_fwd              56  \n",
      "14  0.0     0.200            None  T10_notrans_mordred_Var             600  \n",
      "15  0.0     0.200            None  T10_notrans_mordred_Lor              17  \n",
      "16  0.0     0.198            None   T10_notrans_mordred_Rf              54  \n",
      "17  0.0     0.194            None  T10_notrans_mordred_fwd              56  \n",
      "18  0.0     0.215            None      T10_std_mordred_Var            1230  \n",
      "19  0.0     0.202            None      T10_std_mordred_Lor             171  \n",
      "20  0.0     0.193            None       T10_std_mordred_Rf              62  \n",
      "21  0.0     0.174            None      T10_std_mordred_fwd              63  \n",
      "22  0.0     0.212            None     T10_rbst_mordred_Var            1162  \n",
      "23  0.0     0.220            None      T10_rbst_mordred_Rf              55  \n",
      "24  0.0     0.175            None     T10_rbst_mordred_fwd              63  \n",
      "25  0.0     0.195            None   T10_minmax_mordred_Var              10  \n",
      "26  0.0     0.187            None   T10_minmax_mordred_Lor              87  \n",
      "27  0.0     0.178            None    T10_minmax_mordred_Rf              61  \n",
      "28  0.0     0.168            None   T10_minmax_mordred_fwd              63  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-c95bc1027ee6>\", line 100, in <module>\n",
      "    ml_workflow(std_records, target_id, targ_dir, cutoffs, thresholds, reg_algo, clas_algo)\n",
      "  File \"<ipython-input-24-90bb7feda03d>\", line 117, in ml_workflow\n",
      "    results = build_models(threshold, frame, featset, name, reg_algo, clas_algo)\n",
      "  File \"<ipython-input-23-6b3325354612>\", line 17, in build_models\n",
      "    model_conf = classification.setup(data=frame, target='class', fix_imbalance=fix\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pycaret\\classification.py\", line 580, in setup\n",
      "    return pycaret.internal.tabular.setup(\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pycaret\\internal\\tabular.py\", line 1308, in setup\n",
      "    test_data = prep_pipe.transform(test_data)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 549, in _transform\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pycaret\\internal\\preprocess.py\", line 393, in transform\n",
      "    data[i] = data[i].astype(self.learned_dtypes[i])\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 5546, in astype\n",
      "    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors,)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 595, in astype\n",
      "    return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 406, in apply\n",
      "    applied = getattr(b, f)(**kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 595, in astype\n",
      "    values = astype_nansafe(vals1d, dtype, copy=True)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\", line 995, in astype_nansafe\n",
      "    return arr.astype(dtype, copy=True)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"E:\\Anaconda3\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-c95bc1027ee6>\", line 100, in <module>\n",
      "    ml_workflow(std_records, target_id, targ_dir, cutoffs, thresholds, reg_algo, clas_algo)\n",
      "  File \"<ipython-input-24-90bb7feda03d>\", line 117, in ml_workflow\n",
      "    results = build_models(threshold, frame, featset, name, reg_algo, clas_algo)\n",
      "  File \"<ipython-input-23-6b3325354612>\", line 17, in build_models\n",
      "    model_conf = classification.setup(data=frame, target='class', fix_imbalance=fix\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pycaret\\classification.py\", line 580, in setup\n",
      "    return pycaret.internal.tabular.setup(\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pycaret\\internal\\tabular.py\", line 1308, in setup\n",
      "    test_data = prep_pipe.transform(test_data)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 549, in _transform\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pycaret\\internal\\preprocess.py\", line 393, in transform\n",
      "    data[i] = data[i].astype(self.learned_dtypes[i])\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 5546, in astype\n",
      "    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors,)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 595, in astype\n",
      "    return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 406, in apply\n",
      "    applied = getattr(b, f)(**kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 595, in astype\n",
      "    values = astype_nansafe(vals1d, dtype, copy=True)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\", line 995, in astype_nansafe\n",
      "    return arr.astype(dtype, copy=True)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3435, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"E:\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-c95bc1027ee6>\", line 100, in <module>\n",
      "    ml_workflow(std_records, target_id, targ_dir, cutoffs, thresholds, reg_algo, clas_algo)\n",
      "  File \"<ipython-input-24-90bb7feda03d>\", line 117, in ml_workflow\n",
      "    results = build_models(threshold, frame, featset, name, reg_algo, clas_algo)\n",
      "  File \"<ipython-input-23-6b3325354612>\", line 17, in build_models\n",
      "    model_conf = classification.setup(data=frame, target='class', fix_imbalance=fix\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pycaret\\classification.py\", line 580, in setup\n",
      "    return pycaret.internal.tabular.setup(\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pycaret\\internal\\tabular.py\", line 1308, in setup\n",
      "    test_data = prep_pipe.transform(test_data)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 549, in _transform\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pycaret\\internal\\preprocess.py\", line 393, in transform\n",
      "    data[i] = data[i].astype(self.learned_dtypes[i])\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 5546, in astype\n",
      "    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors,)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 595, in astype\n",
      "    return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 406, in apply\n",
      "    applied = getattr(b, f)(**kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 595, in astype\n",
      "    values = astype_nansafe(vals1d, dtype, copy=True)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\", line 995, in astype_nansafe\n",
      "    return arr.astype(dtype, copy=True)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3435, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"E:\\Anaconda3\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"E:\\Anaconda3\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings('ignore')\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # get the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #options for the user to choose\n",
    "    options = ['ChEMBL target list', 'Molecules list']\n",
    "    # create a easygui choice box window to get input from user\n",
    "    choice = easygui.choicebox(msg='Choose the input file type:'\n",
    "                               , title='Input list and file'\n",
    "                               , choices=options\n",
    "                               , preselect=[])\n",
    "    print('Selected {} as input list.'.format(choice))\n",
    "    \n",
    "    # input for the ChEMBL Target ID List\n",
    "    if choice == options[0]:\n",
    "        input_file = easygui.fileopenbox(title='Select the {} file'.format(choice),\n",
    "                                         default='*txt', filetypes=['*.txt', 'TEXT files'])\n",
    "        print('Input file is {}\\n'.format(input_file))\n",
    "        cutoffs, thresholds = get_thresholds()\n",
    "        if cutoffs is not None:\n",
    "            clas_algo = get_algorithms(thresholds[0])\n",
    "            reg_algo = get_algorithms(thresholds[-1])\n",
    "        else:\n",
    "            clas_algo = None\n",
    "            reg_algo = get_algorithms(thresholds[-1])\n",
    "        try:\n",
    "            # creates an engine to connect to the database using a URL containing\n",
    "            # databasedialect[+driver]://user:password@host/dbname\n",
    "            engine = create_engine(\"postgresql+psycopg2://sarath:jbl@cci@localhost/chembl_27\")\n",
    "            engine.connect()\n",
    "            chembl_web = False\n",
    "        except Exception as e:\n",
    "            chembl_web = True\n",
    "            print('Error: {}'.format(e))\n",
    "        with open(input_file, 'r') as target_ids:\n",
    "            for target_id in target_ids:\n",
    "                target_id = target_id.strip()\n",
    "                # start time for the data fetching\n",
    "                target_start_time = time.time()\n",
    "                # detect the current working directory and create a new directory using the input target id\n",
    "                targ_dir = join(os.getcwd(), target_id)\n",
    "                os.mkdir(targ_dir)\n",
    "                if not chembl_web:\n",
    "                    print('Retrieving the data from chembl_27 database')\n",
    "                    # get data from chembl database\n",
    "                    std_records, test_records = get_data_from_chembldb(target_id, targ_dir, cutoffs, thresholds, choice)\n",
    "                else:\n",
    "                    from chembl_webresource_client.new_client import new_client\n",
    "                    print('Kill the process and rerun the code'\n",
    "                          ' or will retrieve data using chembl webresource client\\n'\n",
    "                          '... ... ... ... ...\\n... ... ... ... ...\\n'\n",
    "                          'Retrieving the data by using chembl webresource client')\n",
    "                    # get data thru chembl web client\n",
    "                    std_records, test_records = get_data_from_chemblwbc(target_id, targ_dir, cutoffs, thresholds, choice)\n",
    "                    #get_data_from_chemblwbc(target_id, targ_dir)\n",
    "                # stop time for the data fetching\n",
    "                data_end_time = time.time()\n",
    "                if (data_end_time-target_start_time) < 60:\n",
    "                    print('|_ {} sec to fetch the standard data'\n",
    "                          ' from ChEMBL-27 database'.format(round(data_end_time-target_start_time, 2)))\n",
    "                else: print('|_ {} min to fetch the standard data'\n",
    "                            ' from ChEMBL-27 database'.format(round((data_end_time-target_start_time)/60, 2)))\n",
    "                ml_workflow(std_records, target_id, targ_dir, cutoffs, thresholds, reg_algo, clas_algo)\n",
    "        \n",
    "    # input for Molecule List\n",
    "    elif choice == options[1]:\n",
    "        # for user input, csv file must contain following column names to execute the code properly\n",
    "        # mol_id, standard_type, pvalue, canonical_smiles\n",
    "        input_file = easygui.fileopenbox(title='Select the {} file'.format(choice)\n",
    "                                         , default='*csv', filetypes=['*.csv', 'CSV files'])\n",
    "        print('Input file is {}\\n'.format(input_file))\n",
    "        target_id = splitext(basename(input_file))[0]\n",
    "        print(basename(input_file))\n",
    "        cutoffs, thresholds = get_thresholds()\n",
    "        if cutoffs is not None:\n",
    "            clas_algo = get_algorithms(thresholds[0])\n",
    "            reg_algo = get_algorithms(thresholds[-1])\n",
    "        else:\n",
    "            clas_algo = None\n",
    "            reg_algo = get_algorithms(thresholds[-1])\n",
    "        # start time for the data fetching\n",
    "        target_start_time = time.time()\n",
    "        # detect the current working directory and create a new directory using the input target id\n",
    "        targ_dir = join(os.getcwd(),target_id)\n",
    "        os.mkdir(targ_dir)\n",
    "        #std_records = pandas.read_csv(input_file)\n",
    "        dataframe = pandas.read_csv(input_file)\n",
    "        std_records = get_std_data(dataframe, 'user_data', cutoffs, choice)\n",
    "        std_records.to_csv('{}_uniquedata.csv'.format(join(targ_dir, target_id)), index=False)\n",
    "        # stop time for the data fetching\n",
    "        data_end_time = time.time()\n",
    "        if (data_end_time-target_start_time) < 60:\n",
    "            print('|_ {} sec to read and standardize the data'\n",
    "                  ' from {}'.format(round(data_end_time-target_start_time, 2), basename(input_file)))\n",
    "        else: print('|_ {} sec to read and standardize the data'\n",
    "                  ' from {}'.format(round((data_end_time-target_start_time)/60, 2)\n",
    "                    , basename(input_file)))\n",
    "        ml_workflow(std_records, target_id, targ_dir, cutoffs, thresholds, reg_algo, clas_algo)\n",
    "        \n",
    "    else: # Error message\n",
    "        easygui.msgbox(msg='Re-run !!! the code and choose a input type.',\n",
    "                       title='Error !!!', ok_button='OK')\n",
    "    print('Job is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
